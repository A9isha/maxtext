{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e206924c-0576-4624-9225-d283ebb135db",
   "metadata": {},
   "source": [
    "# Note: Move this to the home directory of your TPU if you want to load both LingvoTF and MaxText config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c6ed56-3100-4d02-bdbe-c845c67f6a2b",
   "metadata": {},
   "source": [
    "## If creating new checkpoint disable eager mode, if continuing training from the checkpoint written out, enable eager mode, and directly go to MaxText part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93aa9399-7c30-4c4f-924f-0ddf8be630f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 08:55:11.769156: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-10-14 08:55:11.769193: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import lingvo.compat as tf\n",
    "# tf.disable_eager_execution()\n",
    "\n",
    "\n",
    "tf.enable_eager_execution()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22f035ca-1b95-4414-a224-9896c909e420",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 08:50:12.609981: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-10-14 08:50:12.610022: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "#the Lingvot TF experiment\n",
    "module = importlib.import_module('lg-gpt3.lingvo.tasks.lm.params.lg_gpt3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff9e1f7b-5cac-406f-a5e8-5cb2275d1dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'lg-gpt3.lingvo.tasks.lm.params.lg_gpt3' from '/home/mazumdera/lg-gpt3/lingvo/tasks/lm/params/lg_gpt3.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f837b494-9f12-405f-981c-501924117460",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 08:50:27.295618: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-10-14 08:50:27.295650: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-10-14 08:50:27.295680: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (t1v-n-8e231585-w-0): /proc/driver/nvidia/version does not exist\n",
      "2023-10-14 08:50:27.296194: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:absl:gshard_utils.Split is deprecated. Please use gshard_utils.MeshSplit with specific device_mesh and device_mesh_shape set in the Builder.\n",
      "WARNING:absl:gshard_utils.Split is deprecated. Please use gshard_utils.MeshSplit with specific device_mesh and device_mesh_shape set in the Builder.\n",
      "WARNING:absl:gshard_utils.Split is deprecated. Please use gshard_utils.MeshSplit with specific device_mesh and device_mesh_shape set in the Builder.\n",
      "WARNING:absl:gshard_utils.Split is deprecated. Please use gshard_utils.MeshSplit with specific device_mesh and device_mesh_shape set in the Builder.\n",
      "WARNING:absl:gshard_utils.Split is deprecated. Please use gshard_utils.MeshSplit with specific device_mesh and device_mesh_shape set in the Builder.\n",
      "WARNING:absl:gshard_utils.Split is deprecated. Please use gshard_utils.MeshSplit with specific device_mesh and device_mesh_shape set in the Builder.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "tf_model = module.LgTestModel().Task()\n",
    "tf_model = tf_model.Instantiate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae2064f4-b6fe-4b7d-bcfd-c6e7e72dff54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lingvo.core.gshard_builder.UniTransformer at 0x7fee7c0310c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa7cd82d-9b37-484a-940e-3fde34890b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the checkpoint if not already done\n",
    "#!gsutil -m cp -r  \"gs://mazumdera-test-bucket/lingvo/v4-16-LgTestModel-10102023-1/train/*\" ~/lg-lingvo-checkpoint/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6128ae5-8ae5-42f2-962e-8f76f5c31918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "tf_path = os.path.abspath(\n",
    "    './lg-lingvo-checkpoint')  # Path to our TensorFlow checkpoint\n",
    "\n",
    "#load the Lingvo TF checkpoint\n",
    "reader=tf.train.load_checkpoint(tf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c448064c-8b94-41e0-b6d9-8991f565d7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transformer/decoder/final_layer_norm/w/scale/var/Adafactor': [512],\n",
       " 'transformer/decoder/final_layer_norm/w/scale/var': [512],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_000/dec_self_attention/w/wo/var/Adafactor': [384],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_000/dec_self_attention/w/wo/var': [384,\n",
       "  512],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_000/dec_self_attention/w/wk/var/Adafactor_1': [512],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_000/dec_self_attention/w/wk/var/Adafactor': [384],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_000/dec_self_attention/w/wo/var/Adafactor_1': [512],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_001/dense_relu_dense/w/wo/var': [2048,\n",
       "  512],\n",
       " 'transformer/dec_pos_emb/w/embedding/var/Adafactor': [512],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_000/ln/w/scale/var/Adafactor': [512],\n",
       " 'transformer/dec_emb/w/embedding/var/Adafactor_1': [50272],\n",
       " 'transformer/dec_emb/w/embedding/var/Adafactor': [512],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_000/dec_self_attention/w/wk/var': [512,\n",
       "  384],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_000/dec_self_attention/w/wq/var/Adafactor_1': [512],\n",
       " 'transformer/dec_emb/w/embedding/var': [50272, 512],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_000/ln/w/scale/var': [512],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_001/dense_relu_dense/w/wi/var': [512,\n",
       "  2048],\n",
       " 'transformer/dec_pos_emb/w/embedding/var/Adafactor_1': [2048],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_000/dec_self_attention/w/wv/var/Adafactor': [384],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_001/dense_relu_dense/w/wo/var/Adafactor_1': [2048],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_000/dec_self_attention/w/wq/var': [512,\n",
       "  384],\n",
       " 'global_step': [],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_001/dense_relu_dense/w/wo/var/Adafactor': [512],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_000/dec_self_attention/w/wq/var/Adafactor': [384],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_001/dense_relu_dense/w/wi/var/Adafactor_1': [2048],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_000/dec_self_attention/w/wv/var': [512,\n",
       "  384],\n",
       " 'transformer/dec_pos_emb/w/embedding/var': [2048, 512],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_000/dec_self_attention/w/wv/var/Adafactor_1': [512],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_001/dense_relu_dense/w/wi/var/Adafactor': [512],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_001/ln/w/scale/var': [512],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_001/ln/w/scale/var/Adafactor': [512]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_shape_map = reader.get_variable_to_shape_map()\n",
    "ckpt_shape_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be33ccf8-a3a3-4d31-9398-3c5784caf4e2",
   "metadata": {},
   "source": [
    "## MaxText part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c67a2eb-28bb-4a31-a30d-80043574a786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 devices.\n"
     ]
    }
   ],
   "source": [
    "#Get all the imports\n",
    "import jax\n",
    "import os\n",
    "import sys\n",
    "\n",
    "jax.config.update('jax_default_prng_impl', 'unsafe_rbg')\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"0\"\n",
    "os.environ[\"LIBTPU_INIT_ARGS\"] = os.environ.get(\"LIBTPU_INIT_ARGS\",\"\") + \" --xla_tpu_spmd_rng_bit_generator_unsafe=true\"\n",
    "print(f\"Found {jax.device_count()} devices.\")\n",
    "\n",
    "from typing import Sequence\n",
    "import datetime\n",
    "from absl import app\n",
    "from flax.linen import partitioning as nn_partitioning\n",
    "from flax import linen as nn\n",
    "import numpy as np\n",
    "import optax\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from layers import Transformer\n",
    "import pyconfig\n",
    "from input_pipeline import create_data_iterator_with_tokenizer\n",
    "import max_utils\n",
    "import checkpointing\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from jax.sharding import PartitionSpec as P\n",
    "from jax.sharding import Mesh\n",
    "\n",
    "from jax.experimental.compilation_cache import compilation_cache as cc\n",
    "\n",
    "from cloud_tpu_diagnostics import diagnostic\n",
    "from cloud_tpu_diagnostics.configuration import debug_configuration\n",
    "from cloud_tpu_diagnostics.configuration import diagnostic_configuration\n",
    "from cloud_tpu_diagnostics.configuration import stack_trace_configuration\n",
    "\n",
    "import max_utils\n",
    "from jax.sharding import PartitionSpec as P\n",
    "import max_logging\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aec9ef4b-010d-4654-8756-4b2dc11ce76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax.training import train_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d997407-6722-41c1-a952-a75df890866d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_output_directory=\"base_output_directory=gs://mazumdera-test-bucket/maxtext/lg/10142023/1\"\n",
    "file_pattern_for_train_data=\"file_pattern_for_train_data=gs://yejingxin-us-central2/external/lg/dummy-data/train/*.tfrecords\"\n",
    "file_pattern_for_eval_data=\"file_pattern_for_eval_data=gs://yejingxin-us-central2/external/lg/dummy-data/valid/*tfrecords\"\n",
    "base_num_decoder_layers=\"base_num_decoder_layers=1\"\n",
    "base_num_heads = \"base_num_heads=4\"\n",
    "head_nums = \"head_dim=96\"\n",
    "dataset_type = \"dataset_type=lg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df634dba-1afd-4686-bc4f-0e02e462aa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "commandline_args = [\"dummy\", \"/home/mazumdera/maxtext/MaxText/configs/base.yml\",\"run_name=1xv3-8\", \"dcn_data_parallelism=1\", \"save_period=5\",\"ici_data_parallelism=4\",\"ici_tensor_parallelism=2\",\"steps=20\",\"enable_profiler=true\",\"remat_policy=full\",\"base_emb_dim=512\", base_num_heads, head_nums,\"vocab_size=50272\", base_num_decoder_layers, \"per_device_batch_size=0.5\",\"enable_profiler=true\", \"base_mlp_dim=2048\", file_pattern_for_train_data, file_pattern_for_eval_data, base_output_directory, dataset_type,\"max_predict_length=512\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3d3587f-6061-476a-aabb-514e52852b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyconfig.initialize(commandline_args)\n",
    "config = pyconfig.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2de289f-6468-48cd-bc4c-899d614e7f1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating checkpoint manager...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 08:55:43.536689: I external/xla/xla/pjrt/distributed/service.cc:492] Experimental coordination service is enabled.\n",
      "2023-10-14 08:55:43.536971: I external/xla/xla/pjrt/distributed/service.cc:524] Jax service listening on 10.128.0.69:43329\n",
      "2023-10-14 08:55:43.537720: I external/tsl/tsl/distributed_runtime/coordination/coordination_service.cc:551] /job:jax_worker/replica:0/task:0 has connected to coordination service. Incarnation: 8997740297104136765\n",
      "2023-10-14 08:55:43.537868: I external/tsl/tsl/distributed_runtime/coordination/coordination_service_agent.cc:299] Coordination agent has successfully connected.\n",
      "2023-10-14 08:55:43.538114: I external/xla/xla/pjrt/distributed/client.cc:508] Connected to distributed JAX controller\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint manager created!\n"
     ]
    }
   ],
   "source": [
    "checkpoint_manager = checkpointing.create_orbax_checkpoint_manager(\n",
    "      config.checkpoint_dir,\n",
    "      config.enable_checkpointing,\n",
    "      config.async_checkpointing,\n",
    "      config.save_period,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c83c248d-20ba-4fb7-b207-b5c7ff42d1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial PRNG Keys\n",
    "init_rng, nextrng = random.split(random.PRNGKey(config.init_weights_seed), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a14c500-a646-4f82-8a82-3702b16c26a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Devices: [TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0), TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1), TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0), TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1), TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0), TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1), TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0), TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)] (num_devices: 8)\n",
      "Decided on mesh: [[[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0)\n",
      "   TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1)]]\n",
      "\n",
      " [[TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0)\n",
      "   TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1)]]\n",
      "\n",
      " [[TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0)\n",
      "   TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]]\n",
      "\n",
      " [[TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0)\n",
      "   TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1)]]]\n"
     ]
    }
   ],
   "source": [
    "devices_array = max_utils.create_device_mesh(config)\n",
    "mesh = Mesh(devices_array, config.mesh_axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd4ec8b3-c764-42f9-aa44-d58020e2b2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(config, mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8c3219a-43ce-40dd-9ab6-87140245a933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: also compare with optax.adafactor\n",
    "tx = optax.adamw(\n",
    "      max_utils.create_learning_rate_schedule(config),\n",
    "      b1=config.adam_b1,\n",
    "      b2=config.adam_b2,\n",
    "      eps=config.adam_eps,\n",
    "      eps_root=config.adam_eps_root,\n",
    "      weight_decay=config.adam_weight_decay,\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8310d6-b14d-4951-bb94-902e9d88408b",
   "metadata": {},
   "source": [
    "## Run the following cells if creating the tranlated ckpt, else skip to running the new ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a65c97ad-03ee-48af-9bc8-af6407a79b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing checkpoints found, not restoring checkpoint.\n"
     ]
    }
   ],
   "source": [
    "state, state_mesh_annotations = max_utils.setup_initial_state(model, tx, config, init_rng, mesh, checkpoint_manager)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23992c32-f490-4636-9e0d-95996e662750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import max_utils\n",
    "init_train_state_partial = functools.partial(max_utils.init_train_state, model, tx,\n",
    "                                               config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19c203e7-82ce-42a9-a6fd-1e80b1b654fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainState(step=ShapeDtypeStruct(shape=(), dtype=int32), apply_fn=<bound method Module.apply of Transformer(\n",
       "    # attributes\n",
       "    config = <pyconfig.HyperParameters object at 0x7fee7a3a7c10>\n",
       "    mesh = Mesh(device_ids=array([[[0, 1]],\n",
       "    \n",
       "           [[2, 3]],\n",
       "    \n",
       "           [[6, 7]],\n",
       "    \n",
       "           [[4, 5]]]), axis_names=('data', 'fsdp', 'tensor'))\n",
       ")>, params={'decoder': {'decoder': {'mlp': {'wi': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 1, 2048), dtype=float32), names=('embed', 'layers', 'mlp'), mesh=None, rules=None)}, 'wo': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(2048, 1, 512), dtype=float32), names=('mlp', 'layers', 'embed'), mesh=None, rules=None)}}, 'pre_self_attention_layer_norm': {'scale': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 1), dtype=float32), names=('embed', 'layers'), mesh=None, rules=None)}, 'relpos_bias': {'rel_embedding': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(4, 1, 32), dtype=float32), names=('heads', 'layers', 'relpos_buckets'), mesh=None, rules=None)}, 'self_attention': {'key': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 1, 4, 96), dtype=float32), names=('embed', 'layers', 'heads', 'kv'), mesh=None, rules=None)}, 'key_layer_norm': {'scale': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(96, 1), dtype=float32), names=('heads', 'layers'), mesh=None, rules=None)}, 'out': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(4, 1, 96, 512), dtype=float32), names=('heads', 'layers', 'kv', 'embed'), mesh=None, rules=None)}, 'query': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 1, 4, 96), dtype=float32), names=('embed', 'layers', 'heads', 'kv'), mesh=None, rules=None)}, 'query_layer_norm': {'scale': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(96, 1), dtype=float32), names=('heads', 'layers'), mesh=None, rules=None)}, 'value': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 1, 4, 96), dtype=float32), names=('embed', 'layers', 'heads', 'kv'), mesh=None, rules=None)}}}, 'decoder_norm': {'scale': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512,), dtype=float32), names=('embed',), mesh=None, rules=None)}}, 'token_embedder': {'embedding': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(50272, 512), dtype=float32), names=('vocab', 'embed'), mesh=None, rules=None)}}, tx=GradientTransformationExtraArgs(init=<function chain.<locals>.init_fn at 0x7feb011e08b0>, update=<function chain.<locals>.update_fn at 0x7feb011e0af0>), opt_state=(ScaleByAdamState(count=ShapeDtypeStruct(shape=(), dtype=int32), mu={'decoder': {'decoder': {'mlp': {'wi': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 1, 2048), dtype=float32), names=('embed', 'layers', 'mlp'), mesh=None, rules=None)}, 'wo': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(2048, 1, 512), dtype=float32), names=('mlp', 'layers', 'embed'), mesh=None, rules=None)}}, 'pre_self_attention_layer_norm': {'scale': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 1), dtype=float32), names=('embed', 'layers'), mesh=None, rules=None)}, 'relpos_bias': {'rel_embedding': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(4, 1, 32), dtype=float32), names=('heads', 'layers', 'relpos_buckets'), mesh=None, rules=None)}, 'self_attention': {'key': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 1, 4, 96), dtype=float32), names=('embed', 'layers', 'heads', 'kv'), mesh=None, rules=None)}, 'key_layer_norm': {'scale': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(96, 1), dtype=float32), names=('heads', 'layers'), mesh=None, rules=None)}, 'out': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(4, 1, 96, 512), dtype=float32), names=('heads', 'layers', 'kv', 'embed'), mesh=None, rules=None)}, 'query': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 1, 4, 96), dtype=float32), names=('embed', 'layers', 'heads', 'kv'), mesh=None, rules=None)}, 'query_layer_norm': {'scale': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(96, 1), dtype=float32), names=('heads', 'layers'), mesh=None, rules=None)}, 'value': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 1, 4, 96), dtype=float32), names=('embed', 'layers', 'heads', 'kv'), mesh=None, rules=None)}}}, 'decoder_norm': {'scale': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512,), dtype=float32), names=('embed',), mesh=None, rules=None)}}, 'token_embedder': {'embedding': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(50272, 512), dtype=float32), names=('vocab', 'embed'), mesh=None, rules=None)}}, nu={'decoder': {'decoder': {'mlp': {'wi': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 1, 2048), dtype=float32), names=('embed', 'layers', 'mlp'), mesh=None, rules=None)}, 'wo': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(2048, 1, 512), dtype=float32), names=('mlp', 'layers', 'embed'), mesh=None, rules=None)}}, 'pre_self_attention_layer_norm': {'scale': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 1), dtype=float32), names=('embed', 'layers'), mesh=None, rules=None)}, 'relpos_bias': {'rel_embedding': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(4, 1, 32), dtype=float32), names=('heads', 'layers', 'relpos_buckets'), mesh=None, rules=None)}, 'self_attention': {'key': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 1, 4, 96), dtype=float32), names=('embed', 'layers', 'heads', 'kv'), mesh=None, rules=None)}, 'key_layer_norm': {'scale': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(96, 1), dtype=float32), names=('heads', 'layers'), mesh=None, rules=None)}, 'out': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(4, 1, 96, 512), dtype=float32), names=('heads', 'layers', 'kv', 'embed'), mesh=None, rules=None)}, 'query': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 1, 4, 96), dtype=float32), names=('embed', 'layers', 'heads', 'kv'), mesh=None, rules=None)}, 'query_layer_norm': {'scale': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(96, 1), dtype=float32), names=('heads', 'layers'), mesh=None, rules=None)}, 'value': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 1, 4, 96), dtype=float32), names=('embed', 'layers', 'heads', 'kv'), mesh=None, rules=None)}}}, 'decoder_norm': {'scale': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512,), dtype=float32), names=('embed',), mesh=None, rules=None)}}, 'token_embedder': {'embedding': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(50272, 512), dtype=float32), names=('vocab', 'embed'), mesh=None, rules=None)}}), EmptyState(), ScaleByScheduleState(count=ShapeDtypeStruct(shape=(), dtype=int32))))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the flax.training.train_state.TrainState\n",
    "abstract_state = jax.eval_shape(init_train_state_partial, init_rng)\n",
    "abstract_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52e2c259-9d85-4398-80c1-9d084734d1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainState(step=PartitionSpec(), apply_fn=<bound method Module.apply of Transformer(\n",
       "    # attributes\n",
       "    config = <pyconfig.HyperParameters object at 0x7fee7a3a7c10>\n",
       "    mesh = Mesh(device_ids=array([[[0, 1]],\n",
       "    \n",
       "           [[2, 3]],\n",
       "    \n",
       "           [[6, 7]],\n",
       "    \n",
       "           [[4, 5]]]), axis_names=('data', 'fsdp', 'tensor'))\n",
       ")>, params={'decoder': {'decoder': {'mlp': {'wi': {'kernel': PartitionSpec('embed', 'layers', 'mlp')}, 'wo': {'kernel': PartitionSpec('mlp', 'layers', 'embed')}}, 'pre_self_attention_layer_norm': {'scale': PartitionSpec('embed', 'layers')}, 'relpos_bias': {'rel_embedding': PartitionSpec('heads', 'layers', 'relpos_buckets')}, 'self_attention': {'key': {'kernel': PartitionSpec('embed', 'layers', 'heads', 'kv')}, 'key_layer_norm': {'scale': PartitionSpec('heads', 'layers')}, 'out': {'kernel': PartitionSpec('heads', 'layers', 'kv', 'embed')}, 'query': {'kernel': PartitionSpec('embed', 'layers', 'heads', 'kv')}, 'query_layer_norm': {'scale': PartitionSpec('heads', 'layers')}, 'value': {'kernel': PartitionSpec('embed', 'layers', 'heads', 'kv')}}}, 'decoder_norm': {'scale': PartitionSpec('embed',)}}, 'token_embedder': {'embedding': PartitionSpec('vocab', 'embed')}}, tx=GradientTransformationExtraArgs(init=<function chain.<locals>.init_fn at 0x7feb011e08b0>, update=<function chain.<locals>.update_fn at 0x7feb011e0af0>), opt_state=(ScaleByAdamState(count=PartitionSpec(), mu={'decoder': {'decoder': {'mlp': {'wi': {'kernel': PartitionSpec('embed', 'layers', 'mlp')}, 'wo': {'kernel': PartitionSpec('mlp', 'layers', 'embed')}}, 'pre_self_attention_layer_norm': {'scale': PartitionSpec('embed', 'layers')}, 'relpos_bias': {'rel_embedding': PartitionSpec('heads', 'layers', 'relpos_buckets')}, 'self_attention': {'key': {'kernel': PartitionSpec('embed', 'layers', 'heads', 'kv')}, 'key_layer_norm': {'scale': PartitionSpec('heads', 'layers')}, 'out': {'kernel': PartitionSpec('heads', 'layers', 'kv', 'embed')}, 'query': {'kernel': PartitionSpec('embed', 'layers', 'heads', 'kv')}, 'query_layer_norm': {'scale': PartitionSpec('heads', 'layers')}, 'value': {'kernel': PartitionSpec('embed', 'layers', 'heads', 'kv')}}}, 'decoder_norm': {'scale': PartitionSpec('embed',)}}, 'token_embedder': {'embedding': PartitionSpec('vocab', 'embed')}}, nu={'decoder': {'decoder': {'mlp': {'wi': {'kernel': PartitionSpec('embed', 'layers', 'mlp')}, 'wo': {'kernel': PartitionSpec('mlp', 'layers', 'embed')}}, 'pre_self_attention_layer_norm': {'scale': PartitionSpec('embed', 'layers')}, 'relpos_bias': {'rel_embedding': PartitionSpec('heads', 'layers', 'relpos_buckets')}, 'self_attention': {'key': {'kernel': PartitionSpec('embed', 'layers', 'heads', 'kv')}, 'key_layer_norm': {'scale': PartitionSpec('heads', 'layers')}, 'out': {'kernel': PartitionSpec('heads', 'layers', 'kv', 'embed')}, 'query': {'kernel': PartitionSpec('embed', 'layers', 'heads', 'kv')}, 'query_layer_norm': {'scale': PartitionSpec('heads', 'layers')}, 'value': {'kernel': PartitionSpec('embed', 'layers', 'heads', 'kv')}}}, 'decoder_norm': {'scale': PartitionSpec('embed',)}}, 'token_embedder': {'embedding': PartitionSpec('vocab', 'embed')}}), EmptyState(), ScaleByScheduleState(count=PartitionSpec())))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "state_logical_annotations = nn.get_partition_spec(abstract_state)\n",
    "state_logical_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b37f119-2941-4547-86f3-19c649261a1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainState(step=ShapeDtypeStruct(shape=(), dtype=int32), apply_fn=<bound method Module.apply of Transformer(\n",
       "    # attributes\n",
       "    config = <pyconfig.HyperParameters object at 0x7fee7a3a7c10>\n",
       "    mesh = Mesh(device_ids=array([[[0, 1]],\n",
       "    \n",
       "           [[2, 3]],\n",
       "    \n",
       "           [[6, 7]],\n",
       "    \n",
       "           [[4, 5]]]), axis_names=('data', 'fsdp', 'tensor'))\n",
       ")>, params={'decoder': {'decoder': {'mlp': {'wi': {'kernel': ShapeDtypeStruct(shape=(512, 1, 2048), dtype=float32)}, 'wo': {'kernel': ShapeDtypeStruct(shape=(2048, 1, 512), dtype=float32)}}, 'pre_self_attention_layer_norm': {'scale': ShapeDtypeStruct(shape=(512, 1), dtype=float32)}, 'relpos_bias': {'rel_embedding': ShapeDtypeStruct(shape=(4, 1, 32), dtype=float32)}, 'self_attention': {'key': {'kernel': ShapeDtypeStruct(shape=(512, 1, 4, 96), dtype=float32)}, 'key_layer_norm': {'scale': ShapeDtypeStruct(shape=(96, 1), dtype=float32)}, 'out': {'kernel': ShapeDtypeStruct(shape=(4, 1, 96, 512), dtype=float32)}, 'query': {'kernel': ShapeDtypeStruct(shape=(512, 1, 4, 96), dtype=float32)}, 'query_layer_norm': {'scale': ShapeDtypeStruct(shape=(96, 1), dtype=float32)}, 'value': {'kernel': ShapeDtypeStruct(shape=(512, 1, 4, 96), dtype=float32)}}}, 'decoder_norm': {'scale': ShapeDtypeStruct(shape=(512,), dtype=float32)}}, 'token_embedder': {'embedding': ShapeDtypeStruct(shape=(50272, 512), dtype=float32)}}, tx=GradientTransformationExtraArgs(init=<function chain.<locals>.init_fn at 0x7feb011e08b0>, update=<function chain.<locals>.update_fn at 0x7feb011e0af0>), opt_state=(ScaleByAdamState(count=ShapeDtypeStruct(shape=(), dtype=int32), mu={'decoder': {'decoder': {'mlp': {'wi': {'kernel': ShapeDtypeStruct(shape=(512, 1, 2048), dtype=float32)}, 'wo': {'kernel': ShapeDtypeStruct(shape=(2048, 1, 512), dtype=float32)}}, 'pre_self_attention_layer_norm': {'scale': ShapeDtypeStruct(shape=(512, 1), dtype=float32)}, 'relpos_bias': {'rel_embedding': ShapeDtypeStruct(shape=(4, 1, 32), dtype=float32)}, 'self_attention': {'key': {'kernel': ShapeDtypeStruct(shape=(512, 1, 4, 96), dtype=float32)}, 'key_layer_norm': {'scale': ShapeDtypeStruct(shape=(96, 1), dtype=float32)}, 'out': {'kernel': ShapeDtypeStruct(shape=(4, 1, 96, 512), dtype=float32)}, 'query': {'kernel': ShapeDtypeStruct(shape=(512, 1, 4, 96), dtype=float32)}, 'query_layer_norm': {'scale': ShapeDtypeStruct(shape=(96, 1), dtype=float32)}, 'value': {'kernel': ShapeDtypeStruct(shape=(512, 1, 4, 96), dtype=float32)}}}, 'decoder_norm': {'scale': ShapeDtypeStruct(shape=(512,), dtype=float32)}}, 'token_embedder': {'embedding': ShapeDtypeStruct(shape=(50272, 512), dtype=float32)}}, nu={'decoder': {'decoder': {'mlp': {'wi': {'kernel': ShapeDtypeStruct(shape=(512, 1, 2048), dtype=float32)}, 'wo': {'kernel': ShapeDtypeStruct(shape=(2048, 1, 512), dtype=float32)}}, 'pre_self_attention_layer_norm': {'scale': ShapeDtypeStruct(shape=(512, 1), dtype=float32)}, 'relpos_bias': {'rel_embedding': ShapeDtypeStruct(shape=(4, 1, 32), dtype=float32)}, 'self_attention': {'key': {'kernel': ShapeDtypeStruct(shape=(512, 1, 4, 96), dtype=float32)}, 'key_layer_norm': {'scale': ShapeDtypeStruct(shape=(96, 1), dtype=float32)}, 'out': {'kernel': ShapeDtypeStruct(shape=(4, 1, 96, 512), dtype=float32)}, 'query': {'kernel': ShapeDtypeStruct(shape=(512, 1, 4, 96), dtype=float32)}, 'query_layer_norm': {'scale': ShapeDtypeStruct(shape=(96, 1), dtype=float32)}, 'value': {'kernel': ShapeDtypeStruct(shape=(512, 1, 4, 96), dtype=float32)}}}, 'decoder_norm': {'scale': ShapeDtypeStruct(shape=(512,), dtype=float32)}}, 'token_embedder': {'embedding': ShapeDtypeStruct(shape=(50272, 512), dtype=float32)}}), EmptyState(), ScaleByScheduleState(count=ShapeDtypeStruct(shape=(), dtype=int32))))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unboxed_abstract_state = max_utils.unbox_logicallypartioned_trainstate(abstract_state)\n",
    "unboxed_abstract_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "729f70c2-2cfa-487f-94ce-c71945cfc0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:jax._src.compilation_cache:Initialized persistent compilation cache at /home/mazumdera/jax_cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 devices.\n",
      "Total num of params = 28624192\n"
     ]
    }
   ],
   "source": [
    "#Num of params in the MaxText config\n",
    "\n",
    "from train import calculate_num_params_from_pytree\n",
    "print(f\"Total num of params = {calculate_num_params_from_pytree(state.params)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a66526f-45d9-4884-9ebf-c7110af0297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Let us consider we are saving a state at step 0 at the vanilla state\n",
    "# import max_logging\n",
    "# step = 0\n",
    "# if checkpoint_manager is not None:\n",
    "#       if checkpoint_manager.save(step, state):\n",
    "#         max_logging.log(f\"saved a checkpoint at step {step}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d71823-8b75-4666-8c46-7660032f44a8",
   "metadata": {},
   "source": [
    "## Create a copy of the state and modify this one, and compare with the previous copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c1e3a51-b580-4e63-a9e4-1914b1762c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing checkpoints found, not restoring checkpoint.\n"
     ]
    }
   ],
   "source": [
    "state_new, state_mesh_annotations_new = max_utils.setup_initial_state(model, tx, config, init_rng, mesh, checkpoint_manager)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955df514-7bd2-425f-80ae-8c8dd3879c72",
   "metadata": {},
   "source": [
    "## Update the MaxText state with values from the LingvoTF Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87daa432-f4cb-45ea-9f6c-d7eafb66bfe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_tensor_shape = (384, 512)\n",
      "out_tensor_reshaped.shape = (4, 1, 96, 512)\n",
      "out_tensor.shape = (384, 512)\n",
      "out_tensor_reshaped = [[[[-1.53098423e-02 -6.04504123e-02 -4.67418768e-02 ...  1.24808691e-01\n",
      "    -7.74728283e-02  1.05696999e-01]\n",
      "   [-2.23743562e-02  6.17731847e-02  2.63397992e-02 ...  7.06597120e-02\n",
      "    -1.47394575e-02 -3.44053097e-02]\n",
      "   [-1.35133499e-02  1.27908960e-02 -3.51429805e-02 ... -2.11554449e-02\n",
      "     2.99066640e-02 -4.58324775e-02]\n",
      "   ...\n",
      "   [-1.40595183e-01 -3.62042822e-02 -4.52025309e-02 ... -2.03563389e-03\n",
      "     8.36239606e-02 -8.50903988e-02]\n",
      "   [ 3.52970790e-03  4.84331371e-03  3.11585944e-02 ...  1.71957035e-02\n",
      "     6.75476268e-02  2.61918530e-02]\n",
      "   [-3.52053791e-02 -2.48367134e-02  5.24204113e-02 ... -2.92290971e-02\n",
      "     8.25344473e-02 -4.25014794e-02]]]\n",
      "\n",
      "\n",
      " [[[-5.46128042e-02  1.73444524e-02  7.59419724e-02 ... -1.37610603e-02\n",
      "     7.93458894e-02 -8.05024151e-03]\n",
      "   [-3.50178481e-04 -1.90739534e-04 -7.16518611e-02 ... -1.78389810e-02\n",
      "     7.25608096e-02  7.12766796e-02]\n",
      "   [-2.58596092e-02  1.05899468e-01  5.07297441e-02 ...  3.63582298e-02\n",
      "    -9.46738292e-03 -3.03323865e-02]\n",
      "   ...\n",
      "   [ 3.96385975e-03 -5.58426157e-02  1.16599891e-02 ... -2.41331104e-02\n",
      "    -5.91603108e-02 -1.60718448e-02]\n",
      "   [ 5.79785779e-02 -4.48235460e-02 -5.32880984e-02 ... -1.71847921e-03\n",
      "    -1.29732890e-02  6.27448484e-02]\n",
      "   [ 9.57442597e-02 -2.68857274e-02  2.54248586e-02 ... -1.75755117e-02\n",
      "     3.89628001e-02  1.43811572e-02]]]\n",
      "\n",
      "\n",
      " [[[-2.25944035e-02  9.25395731e-03 -7.03428313e-02 ...  2.44964473e-02\n",
      "    -3.98347266e-02 -2.91124843e-02]\n",
      "   [ 5.90106612e-03  1.17252562e-02 -1.65361986e-02 ... -3.27193663e-02\n",
      "     5.95376678e-02 -1.18257210e-01]\n",
      "   [-4.64575142e-02 -3.38372812e-02 -7.66721070e-02 ...  5.50509468e-02\n",
      "    -5.80235012e-03 -2.36593857e-02]\n",
      "   ...\n",
      "   [ 1.72360782e-02 -2.84603201e-02  2.46595331e-02 ... -3.59008275e-02\n",
      "     5.79281040e-02 -6.57200739e-02]\n",
      "   [-1.56119941e-02 -2.36537568e-02  7.40914717e-02 ...  5.96615523e-02\n",
      "    -7.42267519e-02  2.02608541e-01]\n",
      "   [ 2.92899311e-02 -2.79060490e-02 -6.29094839e-02 ...  4.10319380e-02\n",
      "    -1.31259728e-02 -3.33752920e-04]]]\n",
      "\n",
      "\n",
      " [[[ 6.73577636e-02  4.17044796e-02  1.32450700e-01 ...  4.99991588e-02\n",
      "     3.10833682e-04  4.37860750e-02]\n",
      "   [-4.88101207e-02 -1.36091635e-01 -8.18713829e-02 ...  7.62896910e-02\n",
      "     1.03733003e-01  8.42685774e-02]\n",
      "   [ 7.91944563e-02 -5.06917462e-02  3.91250663e-02 ...  4.47701514e-02\n",
      "    -2.60211900e-02 -5.58614498e-03]\n",
      "   ...\n",
      "   [-5.51526714e-03  8.76177510e-05  8.18280596e-03 ...  4.13967390e-03\n",
      "     5.69838891e-03  1.65489540e-02]\n",
      "   [ 5.83154038e-02  7.56263286e-02 -5.48902899e-02 ... -8.21445137e-02\n",
      "    -5.82782105e-02 -1.47660058e-02]\n",
      "   [ 5.92812896e-02  3.03897858e-02 -2.42469832e-02 ... -1.87539104e-02\n",
      "     5.35196662e-02 -6.28094301e-02]]]]\n",
      "wo shape = (2048, 512)\n",
      "wo_tensor_reshaped.shape = (2048, 1, 512)\n",
      "wo_tensor_reshaped = [[[-0.01676235 -0.03458652  0.01131701 ... -0.01953289  0.00153006\n",
      "    0.02891048]]\n",
      "\n",
      " [[ 0.03180673 -0.00695198 -0.00123927 ... -0.00592408  0.02751354\n",
      "   -0.03217365]]\n",
      "\n",
      " [[-0.02972157 -0.03397092 -0.0276806  ... -0.00447878  0.01068969\n",
      "   -0.00369296]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.03043409  0.00214301 -0.0197832  ... -0.00374525 -0.00819083\n",
      "    0.02820867]]\n",
      "\n",
      " [[-0.03407392  0.0219641  -0.02649361 ...  0.01844307  0.00884809\n",
      "   -0.00114471]]\n",
      "\n",
      " [[ 0.03469707 -0.00144557  0.0165208  ... -0.03673139 -0.01888393\n",
      "    0.0273078 ]]]\n",
      "wk_tensor shape = (512, 384)\n",
      "wk_tensor_reshaped.shape = (512, 1, 4, 96)\n",
      "wk_tensor_reshaped = [[[[ 0.001478   -0.06387381 -0.02403351 ...  0.03544128  0.03901736\n",
      "     0.02317448]\n",
      "   [ 0.0370672  -0.05329111 -0.0610676  ... -0.06802345 -0.01167655\n",
      "     0.01903061]\n",
      "   [-0.04053818  0.04061252 -0.04744643 ...  0.04433629  0.04364399\n",
      "     0.02507173]\n",
      "   [ 0.03146332  0.00227055  0.09165397 ...  0.04362974 -0.06195988\n",
      "     0.03792399]]]\n",
      "\n",
      "\n",
      " [[[-0.00782562  0.07288078  0.03358367 ... -0.00470405  0.04144061\n",
      "    -0.08123236]\n",
      "   [ 0.01134349  0.05005951  0.05616756 ...  0.00289588 -0.02209662\n",
      "     0.0402936 ]\n",
      "   [-0.06038373 -0.05957428  0.01838623 ... -0.02519638 -0.04832887\n",
      "     0.03633735]\n",
      "   [-0.05664966  0.00716879 -0.14414224 ... -0.00517863  0.04159293\n",
      "    -0.03675196]]]\n",
      "\n",
      "\n",
      " [[[-0.00800305  0.05638066 -0.0231595  ...  0.00468186  0.08184923\n",
      "     0.08797904]\n",
      "   [ 0.03473776 -0.01861716  0.05930871 ... -0.02183746 -0.00376584\n",
      "     0.01855806]\n",
      "   [ 0.01709517  0.03674574  0.05339673 ... -0.04766814  0.03764428\n",
      "     0.00044465]\n",
      "   [ 0.0734214   0.06762858  0.10826479 ...  0.01473378 -0.04873519\n",
      "    -0.00846833]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-0.00374032 -0.01255664  0.04048641 ...  0.04929356 -0.01553246\n",
      "    -0.00754914]\n",
      "   [ 0.01157507  0.01386156  0.05159893 ... -0.03849943 -0.05933804\n",
      "    -0.00491238]\n",
      "   [ 0.02218522  0.01236959 -0.03839958 ... -0.10931343 -0.02265869\n",
      "     0.04001956]\n",
      "   [ 0.10042612  0.00744989  0.04554876 ... -0.04270591 -0.01593095\n",
      "    -0.01259991]]]\n",
      "\n",
      "\n",
      " [[[-0.06257113 -0.0297153  -0.06218141 ...  0.02506171 -0.0282565\n",
      "    -0.0386284 ]\n",
      "   [-0.10435004  0.0524441   0.01646108 ...  0.04100674  0.02340098\n",
      "    -0.05631113]\n",
      "   [-0.0182966   0.09858133  0.05191264 ... -0.07654495  0.0769031\n",
      "     0.00538329]\n",
      "   [-0.02509879 -0.00611986  0.01555385 ...  0.02247214  0.03531448\n",
      "    -0.00018102]]]\n",
      "\n",
      "\n",
      " [[[ 0.03295555 -0.05733629 -0.00707312 ...  0.01835418 -0.02102827\n",
      "    -0.02467513]\n",
      "   [ 0.00744693  0.04775186 -0.06249473 ... -0.00802675  0.02910048\n",
      "    -0.00883806]\n",
      "   [ 0.03815857 -0.01885248  0.06504556 ... -0.04666027  0.05622308\n",
      "    -0.00978572]\n",
      "   [ 0.06097006  0.08327906 -0.00678581 ...  0.03273175  0.00684895\n",
      "     0.04962841]]]]\n",
      "wq_tensor shape = (512, 384)\n",
      "wq_tensor_reshaped.shape = (512, 1, 4, 96)\n",
      "wq_tensor_reshaped = [[[[-5.4104710e-03  1.7203463e-04 -6.2971208e-03 ... -8.5535046e-04\n",
      "     7.5941128e-03 -9.6835644e-04]\n",
      "   [ 8.1210220e-03  6.4359658e-04 -5.7087415e-03 ...  6.2879482e-03\n",
      "    -4.0978608e-03  6.7551970e-03]\n",
      "   [-1.0037418e-02  2.3078299e-03  7.4749871e-04 ...  9.7736018e-04\n",
      "    -1.3083235e-03  5.7256563e-07]\n",
      "   [ 5.9045036e-04 -1.8356616e-03  2.8913147e-03 ... -6.3264128e-03\n",
      "     6.7063752e-03  8.4823673e-04]]]\n",
      "\n",
      "\n",
      " [[[-4.5818216e-03 -2.6779813e-03 -7.2456785e-03 ... -6.1639440e-03\n",
      "    -4.9146544e-03 -7.2685187e-04]\n",
      "   [-9.2108753e-03 -3.5886739e-03 -1.6145286e-03 ... -1.9607535e-03\n",
      "     4.8706876e-03 -4.0842937e-03]\n",
      "   [-4.1560037e-03  7.1937073e-04  5.5535738e-03 ... -4.0517826e-04\n",
      "    -5.8324763e-04 -7.3899031e-03]\n",
      "   [ 1.1168710e-03  3.2101525e-03 -5.7028732e-03 ...  5.9507944e-04\n",
      "     9.5960675e-03  3.6938982e-03]]]\n",
      "\n",
      "\n",
      " [[[ 4.3869810e-03 -4.8493161e-03 -7.3906560e-03 ...  1.2573121e-03\n",
      "     2.3027426e-03  3.3948596e-03]\n",
      "   [-6.7391139e-03  1.6205201e-03 -2.9750478e-03 ...  4.0474874e-03\n",
      "     1.4138578e-03  3.4235453e-03]\n",
      "   [ 2.3901595e-03 -7.0003071e-03  5.7126097e-03 ...  9.0133091e-03\n",
      "     2.0772559e-03  3.6785796e-03]\n",
      "   [-7.1708793e-03  3.1454042e-03 -1.3824936e-04 ... -1.6398021e-03\n",
      "    -1.9547329e-03  2.5548486e-03]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-4.3678693e-03  1.3657572e-03 -6.3487631e-03 ... -1.2049007e-03\n",
      "     1.7457230e-03 -7.2229216e-03]\n",
      "   [-1.8497903e-03  3.3981358e-03  5.7077166e-03 ... -1.6050404e-03\n",
      "     6.3075647e-03 -2.8299552e-03]\n",
      "   [-2.3587001e-03  4.2666504e-03  3.5922627e-03 ...  5.4852664e-03\n",
      "    -2.9393923e-03 -2.3287530e-03]\n",
      "   [-3.5835470e-03 -2.0432596e-04  1.6645996e-03 ... -2.3601495e-03\n",
      "    -8.8062184e-04 -7.5291572e-03]]]\n",
      "\n",
      "\n",
      " [[[ 2.2343250e-03 -5.0007626e-03 -8.5369805e-03 ...  3.0340403e-03\n",
      "    -4.4674724e-03  6.6474912e-04]\n",
      "   [-8.8384869e-03  4.7380854e-03 -1.8574417e-03 ...  6.2918724e-03\n",
      "    -1.1095109e-02 -6.5754773e-03]\n",
      "   [-1.0505755e-02  1.9529605e-03  1.6101969e-03 ... -3.0111528e-03\n",
      "    -5.5476408e-03 -2.9536048e-03]\n",
      "   [-1.1426744e-03 -6.8733189e-03 -2.8854399e-03 ... -1.4450295e-03\n",
      "     3.8202209e-03  1.2970635e-02]]]\n",
      "\n",
      "\n",
      " [[[ 1.1678679e-02  7.0668356e-03 -7.7014477e-03 ...  2.9315441e-03\n",
      "    -2.1239459e-03  3.0079274e-03]\n",
      "   [-4.5918794e-03 -1.0629598e-02 -7.5603975e-03 ... -1.5760167e-03\n",
      "     1.1423288e-03  3.5266716e-05]\n",
      "   [-2.8781828e-03 -5.7655689e-03 -1.2077360e-03 ... -2.2809878e-03\n",
      "    -1.3985480e-02  1.0820305e-03]\n",
      "   [-2.0921861e-03 -2.0787925e-03 -1.3574993e-03 ...  4.0169313e-04\n",
      "    -2.3620848e-03  8.0426020e-04]]]]\n",
      "wv_tensor shape = (512, 384)\n",
      "wv_tensor_reshaped.shape = (512, 1, 4, 96)\n",
      "wv_tensor_reshaped = [[[[ 0.02091645  0.02358255  0.02142744 ... -0.02656077 -0.06501887\n",
      "     0.04066276]\n",
      "   [-0.00670153  0.10092576  0.04731497 ...  0.05571823 -0.04068466\n",
      "     0.00176392]\n",
      "   [ 0.08080532 -0.03481741 -0.01227686 ... -0.05863866 -0.01997565\n",
      "    -0.04828609]\n",
      "   [ 0.01682253 -0.01182118  0.05844316 ... -0.02476276 -0.06148012\n",
      "     0.04632429]]]\n",
      "\n",
      "\n",
      " [[[ 0.01253487  0.01774441 -0.02157787 ... -0.02078455  0.09485175\n",
      "     0.02593191]\n",
      "   [-0.0420789  -0.03250416  0.03336175 ...  0.0252719   0.03868514\n",
      "     0.02952588]\n",
      "   [-0.05444803 -0.03807095  0.04433057 ... -0.02091465 -0.06379214\n",
      "     0.05198651]\n",
      "   [-0.03467688  0.03523512 -0.02499167 ... -0.00341945 -0.06732657\n",
      "    -0.04151217]]]\n",
      "\n",
      "\n",
      " [[[ 0.0298628   0.08953542  0.06959137 ... -0.04754689  0.08013334\n",
      "    -0.00023528]\n",
      "   [ 0.01669084 -0.02034173 -0.01840453 ...  0.05069909  0.03755856\n",
      "     0.01078972]\n",
      "   [-0.04478998 -0.01278179 -0.03065234 ...  0.01038533  0.01056994\n",
      "     0.02352   ]\n",
      "   [-0.03738077 -0.04759693 -0.02586436 ... -0.05320594  0.07288589\n",
      "     0.03723022]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-0.03007956 -0.01642445 -0.01718055 ...  0.03744445 -0.0081796\n",
      "    -0.03403591]\n",
      "   [-0.000652    0.03997058  0.06135172 ...  0.07639247 -0.01234812\n",
      "    -0.06258182]\n",
      "   [ 0.00521617  0.01713975 -0.020371   ... -0.02361702 -0.02306608\n",
      "     0.05416523]\n",
      "   [ 0.00312106  0.00629222  0.03092084 ...  0.01017902 -0.02967714\n",
      "    -0.03192928]]]\n",
      "\n",
      "\n",
      " [[[-0.04071404 -0.00439653 -0.0010738  ... -0.01843453  0.00242812\n",
      "    -0.0131525 ]\n",
      "   [ 0.05014816  0.01704454  0.03617398 ... -0.00834663 -0.02447422\n",
      "    -0.03328159]\n",
      "   [ 0.0126526   0.05645002  0.04493758 ...  0.05384424 -0.00407902\n",
      "     0.01722291]\n",
      "   [-0.02654424 -0.02272174 -0.06023623 ... -0.01271967  0.02918035\n",
      "     0.04580325]]]\n",
      "\n",
      "\n",
      " [[[-0.00745102  0.01276588  0.04992014 ...  0.03198639 -0.00730993\n",
      "    -0.06401833]\n",
      "   [-0.00312883  0.03496491  0.02249715 ...  0.04080368 -0.01433168\n",
      "    -0.01277181]\n",
      "   [-0.01816739 -0.01764057 -0.0121491  ...  0.03593494 -0.02572928\n",
      "    -0.00303346]\n",
      "   [-0.07045519 -0.01051561 -0.01998172 ...  0.0506659  -0.01381042\n",
      "     0.05531108]]]]\n",
      "wi_tensor shape = (512, 2048)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 08:51:27.256952: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wi_tensor_reshaped.shape = (512, 1, 2048)\n",
      "wi_tensor_reshaped = [[[-0.03641239 -0.03962705  0.05871062 ...  0.07531501 -0.07563277\n",
      "    0.01552885]]\n",
      "\n",
      " [[ 0.0077048  -0.03596908  0.06365027 ...  0.04490145  0.03413538\n",
      "   -0.06831469]]\n",
      "\n",
      " [[-0.01209099 -0.05410476  0.04568633 ...  0.07060074 -0.02464857\n",
      "    0.00637501]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.07429314 -0.02990046 -0.05796176 ... -0.05946061 -0.03993283\n",
      "   -0.01406334]]\n",
      "\n",
      " [[ 0.02112295  0.00023006  0.06490169 ...  0.06899361 -0.04490572\n",
      "   -0.01001916]]\n",
      "\n",
      " [[-0.01463708  0.05100304  0.03406622 ... -0.06231261 -0.0555151\n",
      "    0.06860438]]]\n",
      "embedding_tensor shape = (50272, 512)\n",
      "embedding_tensor.shape = (50272, 512)\n"
     ]
    }
   ],
   "source": [
    "with sess.as_default():\n",
    "    \n",
    "    #mlp mapping\n",
    "    out_tensor = reader.get_tensor('transformer/decoder/blocks/iter_00000/blocks_body/layer_000/dec_self_attention/w/wo/var')\n",
    "    print(f\"out_tensor_shape = {out_tensor.shape}\")\n",
    "    out_tensor_reshaped = sess.run(tf.reshape(out_tensor, [config.base_num_heads, config.base_num_decoder_layers, config.head_dim,config.base_emb_dim]))\n",
    "    print(f\"out_tensor_reshaped.shape = {out_tensor_reshaped.shape}\")\n",
    "    print(f\"out_tensor.shape = {out_tensor.shape}\")\n",
    "    print(f\"out_tensor_reshaped = {out_tensor_reshaped}\")\n",
    "    state_new.params['decoder']['decoder']['self_attention']['out']['kernel'] = out_tensor_reshaped\n",
    "\n",
    "    \n",
    "    wo_tensor = reader.get_tensor('transformer/decoder/blocks/iter_00000/blocks_body/layer_001/dense_relu_dense/w/wo/var')\n",
    "    print(f\"wo shape = {wo_tensor.shape}\")\n",
    "    wo_tensor_reshaped = sess.run(tf.reshape(wo_tensor, [config.base_mlp_dim,config.base_num_decoder_layers, config.base_emb_dim]))\n",
    "    print(f\"wo_tensor_reshaped.shape = {wo_tensor_reshaped.shape}\")\n",
    "    print(f\"wo_tensor_reshaped = {wo_tensor_reshaped}\")\n",
    "    state_new.params['decoder']['decoder']['mlp']['wo']['kernel'] = wo_tensor_reshaped\n",
    "\n",
    "    wk_tensor = reader.get_tensor('transformer/decoder/blocks/iter_00000/blocks_body/layer_000/dec_self_attention/w/wk/var')\n",
    "    print(f\"wk_tensor shape = {wk_tensor.shape}\")\n",
    "    wk_tensor_reshaped = sess.run(tf.reshape(wk_tensor, [config.base_emb_dim,config.base_num_decoder_layers, config.base_num_heads, config.head_dim]))\n",
    "    print(f\"wk_tensor_reshaped.shape = {wk_tensor_reshaped.shape}\")\n",
    "    print(f\"wk_tensor_reshaped = {wk_tensor_reshaped}\")                              \n",
    "    state_new.params['decoder']['decoder']['self_attention']['key']['kernel'] = wk_tensor_reshaped\n",
    "\n",
    "\n",
    "    wq_tensor = reader.get_tensor('transformer/decoder/blocks/iter_00000/blocks_body/layer_000/dec_self_attention/w/wq/var')\n",
    "    print(f\"wq_tensor shape = {wq_tensor.shape}\")\n",
    "    wq_tensor_reshaped = sess.run(tf.reshape(wq_tensor, [config.base_emb_dim,config.base_num_decoder_layers, config.base_num_heads, config.head_dim]))\n",
    "    print(f\"wq_tensor_reshaped.shape = {wq_tensor_reshaped.shape}\")\n",
    "    print(f\"wq_tensor_reshaped = {wq_tensor_reshaped}\")\n",
    "    state_new.params['decoder']['decoder']['self_attention']['query']['kernel'] = wq_tensor_reshaped\n",
    "\n",
    "    wv_tensor = reader.get_tensor('transformer/decoder/blocks/iter_00000/blocks_body/layer_000/dec_self_attention/w/wv/var')\n",
    "    print(f\"wv_tensor shape = {wv_tensor.shape}\")\n",
    "    wv_tensor_reshaped = sess.run(tf.reshape(wv_tensor, [config.base_emb_dim,config.base_num_decoder_layers, config.base_num_heads, config.head_dim]))\n",
    "    print(f\"wv_tensor_reshaped.shape = {wv_tensor_reshaped.shape}\")\n",
    "    print(f\"wv_tensor_reshaped = {wv_tensor_reshaped}\")\n",
    "    state_new.params['decoder']['decoder']['self_attention']['value']['kernel'] = wv_tensor_reshaped\n",
    "\n",
    "    \n",
    "    wi_tensor = reader.get_tensor('transformer/decoder/blocks/iter_00000/blocks_body/layer_001/dense_relu_dense/w/wi/var')\n",
    "    print(f\"wi_tensor shape = {wi_tensor.shape}\")\n",
    "    wi_tensor_reshaped = sess.run(tf.reshape(wi_tensor, [config.base_emb_dim,config.base_num_decoder_layers, config.base_mlp_dim]))\n",
    "    print(f\"wi_tensor_reshaped.shape = {wi_tensor_reshaped.shape}\")\n",
    "    print(f\"wi_tensor_reshaped = {wi_tensor_reshaped}\")\n",
    "    state_new.params['decoder']['decoder']['mlp']['wi']['kernel'] = wi_tensor_reshaped\n",
    "\n",
    "\n",
    "    #input embedding\n",
    "    embedding_tensor = reader.get_tensor('transformer/dec_emb/w/embedding/var')\n",
    "    print(f\"embedding_tensor shape = {embedding_tensor.shape}\")\n",
    "    print(f\"embedding_tensor.shape = {embedding_tensor.shape}\")\n",
    "    state_new.params['token_embedder']['embedding'] = embedding_tensor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2e084b53-3258-45e9-b96f-437acff94bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# state_new.params['decoder']['decoder']['mlp']['wi']['kernel'].shape == state.params['decoder']['decoder']['mlp']['wi']['kernel'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46173418-dce7-463a-a4db-a5acc0b2f424",
   "metadata": {},
   "source": [
    "## Write out the new state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8d23e385-8833-426a-8225-6a4362f8af70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://mazumdera-test-bucket/maxtext/lg/10142023/1/1xv3-8/checkpoints/\n"
     ]
    }
   ],
   "source": [
    "# config.checkpoint_dir\n",
    "# !gsutil ls gs://mazumdera-test-bucket/maxtext/lg/10142023/1/1xv3-8/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5f071c8-f4c6-49e3-9873-674fd61eac19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1697273634.292325  437021 gcs_resource.cc:99] Using default AdmissionQueue with limit 32\n",
      "I0000 00:00:1697273634.294070  438809 google_auth_provider.cc:179] Running on GCE, using service account 630405687483-compute@developer.gserviceaccount.com\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved a checkpoint at step 50\n"
     ]
    }
   ],
   "source": [
    "# #since we know know we are loading checkpoint at step 50\n",
    "step = 50\n",
    "if checkpoint_manager is not None:\n",
    "      if checkpoint_manager.save(step, state_new):\n",
    "        max_logging.log(f\"saved a checkpoint at step {step}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2378b63-0358-4e66-9ec8-ebbac3971420",
   "metadata": {},
   "source": [
    "## Now try training with the newly saved model state but need to restart kernel and start with TF eager mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e1fb60a-22a4-4fb6-942c-7423603306bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restoring state from this run's directory latest step         50\n"
     ]
    }
   ],
   "source": [
    "\n",
    "state_read_from_ckpt, state_mesh_annotations_read_from_ckpt = max_utils.setup_initial_state(model, tx, config, init_rng, mesh, checkpoint_manager)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9be27bf-706e-40a3-9969-b51712367500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainState(step=Array(0, dtype=int32), apply_fn=<bound method Module.apply of Transformer(\n",
       "    # attributes\n",
       "    config = <pyconfig.HyperParameters object at 0x7fcbe3d56620>\n",
       "    mesh = Mesh(device_ids=array([[[0, 1]],\n",
       "    \n",
       "           [[2, 3]],\n",
       "    \n",
       "           [[6, 7]],\n",
       "    \n",
       "           [[4, 5]]]), axis_names=('data', 'fsdp', 'tensor'))\n",
       ")>, params={'decoder': {'decoder': {'mlp': {'wi': {'kernel': Array([[[-0.03641239, -0.03962705,  0.05871062, ...,  0.07531501,\n",
       "         -0.07563277,  0.01552885]],\n",
       "\n",
       "       [[ 0.0077048 , -0.03596908,  0.06365027, ...,  0.04490145,\n",
       "          0.03413538, -0.06831469]],\n",
       "\n",
       "       [[-0.01209099, -0.05410476,  0.04568633, ...,  0.07060074,\n",
       "         -0.02464857,  0.00637501]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.07429314, -0.02990046, -0.05796176, ..., -0.05946061,\n",
       "         -0.03993283, -0.01406334]],\n",
       "\n",
       "       [[ 0.02112295,  0.00023006,  0.06490169, ...,  0.06899361,\n",
       "         -0.04490572, -0.01001916]],\n",
       "\n",
       "       [[-0.01463708,  0.05100304,  0.03406622, ..., -0.06231261,\n",
       "         -0.0555151 ,  0.06860438]]], dtype=float32)}, 'wo': {'kernel': Array([[[-0.01676235, -0.03458652,  0.01131701, ..., -0.01953289,\n",
       "          0.00153006,  0.02891048]],\n",
       "\n",
       "       [[ 0.03180673, -0.00695198, -0.00123927, ..., -0.00592408,\n",
       "          0.02751354, -0.03217365]],\n",
       "\n",
       "       [[-0.02972157, -0.03397092, -0.0276806 , ..., -0.00447878,\n",
       "          0.01068969, -0.00369296]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.03043409,  0.00214301, -0.0197832 , ..., -0.00374525,\n",
       "         -0.00819083,  0.02820867]],\n",
       "\n",
       "       [[-0.03407392,  0.0219641 , -0.02649361, ...,  0.01844307,\n",
       "          0.00884809, -0.00114471]],\n",
       "\n",
       "       [[ 0.03469707, -0.00144557,  0.0165208 , ..., -0.03673139,\n",
       "         -0.01888393,  0.0273078 ]]], dtype=float32)}}, 'pre_self_attention_layer_norm': {'scale': Array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)}, 'relpos_bias': {'rel_embedding': Array([[[ 0.28565556,  0.01826969,  0.18958499,  0.03877533,\n",
       "         -0.08346146,  0.01428006,  0.3626849 , -0.1975944 ,\n",
       "          0.13652094, -0.3419946 ,  0.1804098 ,  0.27090403,\n",
       "         -0.09349727, -0.3694171 , -0.26354858, -0.01649568,\n",
       "          0.32678026, -0.35049888, -0.02902791, -0.0181048 ,\n",
       "          0.3813002 , -0.03110833,  0.18620525,  0.03068921,\n",
       "          0.39486003, -0.33150524, -0.14090282, -0.2917485 ,\n",
       "         -0.18930145, -0.10383511,  0.03015047, -0.18647352]],\n",
       "\n",
       "       [[ 0.29987013, -0.38543877,  0.12848455,  0.31678796,\n",
       "          0.12401459,  0.02528046,  0.14330375,  0.28379756,\n",
       "          0.0850879 , -0.21308443,  0.21233524,  0.08818576,\n",
       "          0.22932334,  0.03424025, -0.24908574,  0.07847163,\n",
       "         -0.30593988,  0.07826139, -0.00746454,  0.21981439,\n",
       "         -0.02301871,  0.21090697, -0.37274554, -0.32240343,\n",
       "          0.38230383, -0.14449862, -0.17466427, -0.12785324,\n",
       "          0.13100141, -0.20091574, -0.07203659,  0.26832223]],\n",
       "\n",
       "       [[-0.2112819 , -0.11273932,  0.13261317, -0.36953643,\n",
       "          0.24961425, -0.10550117, -0.18472958,  0.00910209,\n",
       "          0.13963835,  0.18754622,  0.06570696,  0.31500244,\n",
       "         -0.171421  ,  0.32436714, -0.35775563,  0.3443721 ,\n",
       "          0.3953718 ,  0.3653864 , -0.15786053,  0.17715728,\n",
       "         -0.2825879 , -0.37262943,  0.1968093 ,  0.21709293,\n",
       "         -0.323558  ,  0.4025053 , -0.35899857,  0.17806882,\n",
       "         -0.07344481,  0.38470817,  0.25983715, -0.06581101]],\n",
       "\n",
       "       [[-0.29099882,  0.15919255,  0.05897398,  0.25088292,\n",
       "          0.16107966, -0.03032372, -0.13456151,  0.2081164 ,\n",
       "         -0.10400038, -0.32681316,  0.19038342,  0.24952725,\n",
       "          0.15336068, -0.04624445,  0.04371123, -0.08563356,\n",
       "         -0.28288993, -0.05526039, -0.31748056,  0.01377062,\n",
       "         -0.32639286, -0.08107696, -0.25828886,  0.2873483 ,\n",
       "         -0.03462861,  0.23141494, -0.26109403,  0.33406726,\n",
       "          0.21706705, -0.3582378 ,  0.1519981 ,  0.21697672]]],      dtype=float32)}, 'self_attention': {'key': {'kernel': Array([[[[ 0.001478  , -0.06387381, -0.02403351, ...,  0.03544128,\n",
       "           0.03901736,  0.02317448],\n",
       "         [ 0.0370672 , -0.05329111, -0.0610676 , ..., -0.06802345,\n",
       "          -0.01167655,  0.01903061],\n",
       "         [-0.04053818,  0.04061252, -0.04744643, ...,  0.04433629,\n",
       "           0.04364399,  0.02507173],\n",
       "         [ 0.03146332,  0.00227055,  0.09165397, ...,  0.04362974,\n",
       "          -0.06195988,  0.03792399]]],\n",
       "\n",
       "\n",
       "       [[[-0.00782562,  0.07288078,  0.03358367, ..., -0.00470405,\n",
       "           0.04144061, -0.08123236],\n",
       "         [ 0.01134349,  0.05005951,  0.05616756, ...,  0.00289588,\n",
       "          -0.02209662,  0.0402936 ],\n",
       "         [-0.06038373, -0.05957428,  0.01838623, ..., -0.02519638,\n",
       "          -0.04832887,  0.03633735],\n",
       "         [-0.05664966,  0.00716879, -0.14414224, ..., -0.00517863,\n",
       "           0.04159293, -0.03675196]]],\n",
       "\n",
       "\n",
       "       [[[-0.00800305,  0.05638066, -0.0231595 , ...,  0.00468186,\n",
       "           0.08184923,  0.08797904],\n",
       "         [ 0.03473776, -0.01861716,  0.05930871, ..., -0.02183746,\n",
       "          -0.00376584,  0.01855806],\n",
       "         [ 0.01709517,  0.03674574,  0.05339673, ..., -0.04766814,\n",
       "           0.03764428,  0.00044465],\n",
       "         [ 0.0734214 ,  0.06762858,  0.10826479, ...,  0.01473378,\n",
       "          -0.04873519, -0.00846833]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[-0.00374032, -0.01255664,  0.04048641, ...,  0.04929356,\n",
       "          -0.01553246, -0.00754914],\n",
       "         [ 0.01157507,  0.01386156,  0.05159893, ..., -0.03849943,\n",
       "          -0.05933804, -0.00491238],\n",
       "         [ 0.02218522,  0.01236959, -0.03839958, ..., -0.10931343,\n",
       "          -0.02265869,  0.04001956],\n",
       "         [ 0.10042612,  0.00744989,  0.04554876, ..., -0.04270591,\n",
       "          -0.01593095, -0.01259991]]],\n",
       "\n",
       "\n",
       "       [[[-0.06257113, -0.0297153 , -0.06218141, ...,  0.02506171,\n",
       "          -0.0282565 , -0.0386284 ],\n",
       "         [-0.10435004,  0.0524441 ,  0.01646108, ...,  0.04100674,\n",
       "           0.02340098, -0.05631113],\n",
       "         [-0.0182966 ,  0.09858133,  0.05191264, ..., -0.07654495,\n",
       "           0.0769031 ,  0.00538329],\n",
       "         [-0.02509879, -0.00611986,  0.01555385, ...,  0.02247214,\n",
       "           0.03531448, -0.00018102]]],\n",
       "\n",
       "\n",
       "       [[[ 0.03295555, -0.05733629, -0.00707312, ...,  0.01835418,\n",
       "          -0.02102827, -0.02467513],\n",
       "         [ 0.00744693,  0.04775186, -0.06249473, ..., -0.00802675,\n",
       "           0.02910048, -0.00883806],\n",
       "         [ 0.03815857, -0.01885248,  0.06504556, ..., -0.04666027,\n",
       "           0.05622308, -0.00978572],\n",
       "         [ 0.06097006,  0.08327906, -0.00678581, ...,  0.03273175,\n",
       "           0.00684895,  0.04962841]]]], dtype=float32)}, 'key_layer_norm': {'scale': Array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)}, 'out': {'kernel': Array([[[[-1.53098423e-02, -6.04504123e-02, -4.67418768e-02, ...,\n",
       "           1.24808691e-01, -7.74728283e-02,  1.05696999e-01],\n",
       "         [-2.23743562e-02,  6.17731847e-02,  2.63397992e-02, ...,\n",
       "           7.06597120e-02, -1.47394575e-02, -3.44053097e-02],\n",
       "         [-1.35133499e-02,  1.27908960e-02, -3.51429805e-02, ...,\n",
       "          -2.11554449e-02,  2.99066640e-02, -4.58324775e-02],\n",
       "         ...,\n",
       "         [-1.40595183e-01, -3.62042822e-02, -4.52025309e-02, ...,\n",
       "          -2.03563389e-03,  8.36239606e-02, -8.50903988e-02],\n",
       "         [ 3.52970790e-03,  4.84331371e-03,  3.11585944e-02, ...,\n",
       "           1.71957035e-02,  6.75476268e-02,  2.61918530e-02],\n",
       "         [-3.52053791e-02, -2.48367134e-02,  5.24204113e-02, ...,\n",
       "          -2.92290971e-02,  8.25344473e-02, -4.25014794e-02]]],\n",
       "\n",
       "\n",
       "       [[[-5.46128042e-02,  1.73444524e-02,  7.59419724e-02, ...,\n",
       "          -1.37610603e-02,  7.93458894e-02, -8.05024151e-03],\n",
       "         [-3.50178481e-04, -1.90739534e-04, -7.16518611e-02, ...,\n",
       "          -1.78389810e-02,  7.25608096e-02,  7.12766796e-02],\n",
       "         [-2.58596092e-02,  1.05899468e-01,  5.07297441e-02, ...,\n",
       "           3.63582298e-02, -9.46738292e-03, -3.03323865e-02],\n",
       "         ...,\n",
       "         [ 3.96385975e-03, -5.58426157e-02,  1.16599891e-02, ...,\n",
       "          -2.41331104e-02, -5.91603108e-02, -1.60718448e-02],\n",
       "         [ 5.79785779e-02, -4.48235460e-02, -5.32880984e-02, ...,\n",
       "          -1.71847921e-03, -1.29732890e-02,  6.27448484e-02],\n",
       "         [ 9.57442597e-02, -2.68857274e-02,  2.54248586e-02, ...,\n",
       "          -1.75755117e-02,  3.89628001e-02,  1.43811572e-02]]],\n",
       "\n",
       "\n",
       "       [[[-2.25944035e-02,  9.25395731e-03, -7.03428313e-02, ...,\n",
       "           2.44964473e-02, -3.98347266e-02, -2.91124843e-02],\n",
       "         [ 5.90106612e-03,  1.17252562e-02, -1.65361986e-02, ...,\n",
       "          -3.27193663e-02,  5.95376678e-02, -1.18257210e-01],\n",
       "         [-4.64575142e-02, -3.38372812e-02, -7.66721070e-02, ...,\n",
       "           5.50509468e-02, -5.80235012e-03, -2.36593857e-02],\n",
       "         ...,\n",
       "         [ 1.72360782e-02, -2.84603201e-02,  2.46595331e-02, ...,\n",
       "          -3.59008275e-02,  5.79281040e-02, -6.57200739e-02],\n",
       "         [-1.56119941e-02, -2.36537568e-02,  7.40914717e-02, ...,\n",
       "           5.96615523e-02, -7.42267519e-02,  2.02608541e-01],\n",
       "         [ 2.92899311e-02, -2.79060490e-02, -6.29094839e-02, ...,\n",
       "           4.10319380e-02, -1.31259728e-02, -3.33752920e-04]]],\n",
       "\n",
       "\n",
       "       [[[ 6.73577636e-02,  4.17044796e-02,  1.32450700e-01, ...,\n",
       "           4.99991588e-02,  3.10833682e-04,  4.37860750e-02],\n",
       "         [-4.88101207e-02, -1.36091635e-01, -8.18713829e-02, ...,\n",
       "           7.62896910e-02,  1.03733003e-01,  8.42685774e-02],\n",
       "         [ 7.91944563e-02, -5.06917462e-02,  3.91250663e-02, ...,\n",
       "           4.47701514e-02, -2.60211900e-02, -5.58614498e-03],\n",
       "         ...,\n",
       "         [-5.51526714e-03,  8.76177510e-05,  8.18280596e-03, ...,\n",
       "           4.13967390e-03,  5.69838891e-03,  1.65489540e-02],\n",
       "         [ 5.83154038e-02,  7.56263286e-02, -5.48902899e-02, ...,\n",
       "          -8.21445137e-02, -5.82782105e-02, -1.47660058e-02],\n",
       "         [ 5.92812896e-02,  3.03897858e-02, -2.42469832e-02, ...,\n",
       "          -1.87539104e-02,  5.35196662e-02, -6.28094301e-02]]]],      dtype=float32)}, 'query': {'kernel': Array([[[[-5.4104710e-03,  1.7203463e-04, -6.2971208e-03, ...,\n",
       "          -8.5535046e-04,  7.5941128e-03, -9.6835644e-04],\n",
       "         [ 8.1210220e-03,  6.4359658e-04, -5.7087415e-03, ...,\n",
       "           6.2879482e-03, -4.0978608e-03,  6.7551970e-03],\n",
       "         [-1.0037418e-02,  2.3078299e-03,  7.4749871e-04, ...,\n",
       "           9.7736018e-04, -1.3083235e-03,  5.7256563e-07],\n",
       "         [ 5.9045036e-04, -1.8356616e-03,  2.8913147e-03, ...,\n",
       "          -6.3264128e-03,  6.7063752e-03,  8.4823673e-04]]],\n",
       "\n",
       "\n",
       "       [[[-4.5818216e-03, -2.6779813e-03, -7.2456785e-03, ...,\n",
       "          -6.1639440e-03, -4.9146544e-03, -7.2685187e-04],\n",
       "         [-9.2108753e-03, -3.5886739e-03, -1.6145286e-03, ...,\n",
       "          -1.9607535e-03,  4.8706876e-03, -4.0842937e-03],\n",
       "         [-4.1560037e-03,  7.1937073e-04,  5.5535738e-03, ...,\n",
       "          -4.0517826e-04, -5.8324763e-04, -7.3899031e-03],\n",
       "         [ 1.1168710e-03,  3.2101525e-03, -5.7028732e-03, ...,\n",
       "           5.9507944e-04,  9.5960675e-03,  3.6938982e-03]]],\n",
       "\n",
       "\n",
       "       [[[ 4.3869810e-03, -4.8493161e-03, -7.3906560e-03, ...,\n",
       "           1.2573121e-03,  2.3027426e-03,  3.3948596e-03],\n",
       "         [-6.7391139e-03,  1.6205201e-03, -2.9750478e-03, ...,\n",
       "           4.0474874e-03,  1.4138578e-03,  3.4235453e-03],\n",
       "         [ 2.3901595e-03, -7.0003071e-03,  5.7126097e-03, ...,\n",
       "           9.0133091e-03,  2.0772559e-03,  3.6785796e-03],\n",
       "         [-7.1708793e-03,  3.1454042e-03, -1.3824936e-04, ...,\n",
       "          -1.6398021e-03, -1.9547329e-03,  2.5548486e-03]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[-4.3678693e-03,  1.3657572e-03, -6.3487631e-03, ...,\n",
       "          -1.2049007e-03,  1.7457230e-03, -7.2229216e-03],\n",
       "         [-1.8497903e-03,  3.3981358e-03,  5.7077166e-03, ...,\n",
       "          -1.6050404e-03,  6.3075647e-03, -2.8299552e-03],\n",
       "         [-2.3587001e-03,  4.2666504e-03,  3.5922627e-03, ...,\n",
       "           5.4852664e-03, -2.9393923e-03, -2.3287530e-03],\n",
       "         [-3.5835470e-03, -2.0432596e-04,  1.6645996e-03, ...,\n",
       "          -2.3601495e-03, -8.8062184e-04, -7.5291572e-03]]],\n",
       "\n",
       "\n",
       "       [[[ 2.2343250e-03, -5.0007626e-03, -8.5369805e-03, ...,\n",
       "           3.0340403e-03, -4.4674724e-03,  6.6474912e-04],\n",
       "         [-8.8384869e-03,  4.7380854e-03, -1.8574417e-03, ...,\n",
       "           6.2918724e-03, -1.1095109e-02, -6.5754773e-03],\n",
       "         [-1.0505755e-02,  1.9529605e-03,  1.6101969e-03, ...,\n",
       "          -3.0111528e-03, -5.5476408e-03, -2.9536048e-03],\n",
       "         [-1.1426744e-03, -6.8733189e-03, -2.8854399e-03, ...,\n",
       "          -1.4450295e-03,  3.8202209e-03,  1.2970635e-02]]],\n",
       "\n",
       "\n",
       "       [[[ 1.1678679e-02,  7.0668356e-03, -7.7014477e-03, ...,\n",
       "           2.9315441e-03, -2.1239459e-03,  3.0079274e-03],\n",
       "         [-4.5918794e-03, -1.0629598e-02, -7.5603975e-03, ...,\n",
       "          -1.5760167e-03,  1.1423288e-03,  3.5266716e-05],\n",
       "         [-2.8781828e-03, -5.7655689e-03, -1.2077360e-03, ...,\n",
       "          -2.2809878e-03, -1.3985480e-02,  1.0820305e-03],\n",
       "         [-2.0921861e-03, -2.0787925e-03, -1.3574993e-03, ...,\n",
       "           4.0169313e-04, -2.3620848e-03,  8.0426020e-04]]]],      dtype=float32)}, 'query_layer_norm': {'scale': Array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)}, 'value': {'kernel': Array([[[[ 0.02091645,  0.02358255,  0.02142744, ..., -0.02656077,\n",
       "          -0.06501887,  0.04066276],\n",
       "         [-0.00670153,  0.10092576,  0.04731497, ...,  0.05571823,\n",
       "          -0.04068466,  0.00176392],\n",
       "         [ 0.08080532, -0.03481741, -0.01227686, ..., -0.05863866,\n",
       "          -0.01997565, -0.04828609],\n",
       "         [ 0.01682253, -0.01182118,  0.05844316, ..., -0.02476276,\n",
       "          -0.06148012,  0.04632429]]],\n",
       "\n",
       "\n",
       "       [[[ 0.01253487,  0.01774441, -0.02157787, ..., -0.02078455,\n",
       "           0.09485175,  0.02593191],\n",
       "         [-0.0420789 , -0.03250416,  0.03336175, ...,  0.0252719 ,\n",
       "           0.03868514,  0.02952588],\n",
       "         [-0.05444803, -0.03807095,  0.04433057, ..., -0.02091465,\n",
       "          -0.06379214,  0.05198651],\n",
       "         [-0.03467688,  0.03523512, -0.02499167, ..., -0.00341945,\n",
       "          -0.06732657, -0.04151217]]],\n",
       "\n",
       "\n",
       "       [[[ 0.0298628 ,  0.08953542,  0.06959137, ..., -0.04754689,\n",
       "           0.08013334, -0.00023528],\n",
       "         [ 0.01669084, -0.02034173, -0.01840453, ...,  0.05069909,\n",
       "           0.03755856,  0.01078972],\n",
       "         [-0.04478998, -0.01278179, -0.03065234, ...,  0.01038533,\n",
       "           0.01056994,  0.02352   ],\n",
       "         [-0.03738077, -0.04759693, -0.02586436, ..., -0.05320594,\n",
       "           0.07288589,  0.03723022]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[-0.03007956, -0.01642445, -0.01718055, ...,  0.03744445,\n",
       "          -0.0081796 , -0.03403591],\n",
       "         [-0.000652  ,  0.03997058,  0.06135172, ...,  0.07639247,\n",
       "          -0.01234812, -0.06258182],\n",
       "         [ 0.00521617,  0.01713975, -0.020371  , ..., -0.02361702,\n",
       "          -0.02306608,  0.05416523],\n",
       "         [ 0.00312106,  0.00629222,  0.03092084, ...,  0.01017902,\n",
       "          -0.02967714, -0.03192928]]],\n",
       "\n",
       "\n",
       "       [[[-0.04071404, -0.00439653, -0.0010738 , ..., -0.01843453,\n",
       "           0.00242812, -0.0131525 ],\n",
       "         [ 0.05014816,  0.01704454,  0.03617398, ..., -0.00834663,\n",
       "          -0.02447422, -0.03328159],\n",
       "         [ 0.0126526 ,  0.05645002,  0.04493758, ...,  0.05384424,\n",
       "          -0.00407902,  0.01722291],\n",
       "         [-0.02654424, -0.02272174, -0.06023623, ..., -0.01271967,\n",
       "           0.02918035,  0.04580325]]],\n",
       "\n",
       "\n",
       "       [[[-0.00745102,  0.01276588,  0.04992014, ...,  0.03198639,\n",
       "          -0.00730993, -0.06401833],\n",
       "         [-0.00312883,  0.03496491,  0.02249715, ...,  0.04080368,\n",
       "          -0.01433168, -0.01277181],\n",
       "         [-0.01816739, -0.01764057, -0.0121491 , ...,  0.03593494,\n",
       "          -0.02572928, -0.00303346],\n",
       "         [-0.07045519, -0.01051561, -0.01998172, ...,  0.0506659 ,\n",
       "          -0.01381042,  0.05531108]]]], dtype=float32)}}}, 'decoder_norm': {'scale': Array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1.], dtype=float32)}}, 'token_embedder': {'embedding': Array([[-1.1371106 ,  0.46545574,  0.5895609 , ..., -1.6460556 ,\n",
       "        -1.8100487 , -0.35319814],\n",
       "       [-0.12352072, -0.16055802,  0.19895522, ..., -1.0940112 ,\n",
       "         1.3285795 ,  0.2961597 ],\n",
       "       [ 1.0865668 ,  1.2624966 , -0.13743724, ..., -0.17821878,\n",
       "        -0.23192903,  1.0174904 ],\n",
       "       ...,\n",
       "       [-1.4868546 ,  0.01376661,  0.7688832 , ..., -0.15777647,\n",
       "         0.73761797,  0.7883633 ],\n",
       "       [ 0.8115251 , -0.10021049, -1.5109847 , ...,  0.02099015,\n",
       "         0.34064835,  1.0661777 ],\n",
       "       [ 0.08816832, -1.4914334 ,  0.119343  , ...,  1.4323969 ,\n",
       "         0.8548263 ,  1.528712  ]], dtype=float32)}}, tx=GradientTransformationExtraArgs(init=<function chain.<locals>.init_fn at 0x7fcb35fa2b00>, update=<function chain.<locals>.update_fn at 0x7fcb35fa2d40>), opt_state=(ScaleByAdamState(count=Array(0, dtype=int32), mu={'decoder': {'decoder': {'mlp': {'wi': {'kernel': Array([[[0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)}, 'wo': {'kernel': Array([[[0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)}}, 'pre_self_attention_layer_norm': {'scale': Array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)}, 'relpos_bias': {'rel_embedding': Array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],      dtype=float32)}, 'self_attention': {'key': {'kernel': Array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)}, 'key_layer_norm': {'scale': Array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)}, 'out': {'kernel': Array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)}, 'query': {'kernel': Array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)}, 'query_layer_norm': {'scale': Array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)}, 'value': {'kernel': Array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)}}}, 'decoder_norm': {'scale': Array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0.], dtype=float32)}}, 'token_embedder': {'embedding': Array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)}}, nu={'decoder': {'decoder': {'mlp': {'wi': {'kernel': Array([[[0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)}, 'wo': {'kernel': Array([[[0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)}}, 'pre_self_attention_layer_norm': {'scale': Array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)}, 'relpos_bias': {'rel_embedding': Array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],      dtype=float32)}, 'self_attention': {'key': {'kernel': Array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)}, 'key_layer_norm': {'scale': Array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)}, 'out': {'kernel': Array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)}, 'query': {'kernel': Array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)}, 'query_layer_norm': {'scale': Array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)}, 'value': {'kernel': Array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)}}}, 'decoder_norm': {'scale': Array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0.], dtype=float32)}}, 'token_embedder': {'embedding': Array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)}}), EmptyState(), ScaleByScheduleState(count=Array(0, dtype=int32))))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_read_from_ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "796596ca-80a0-4d3a-926e-04fc1dc2127f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to read training data from path: gs://yejingxin-us-central2/external/lg/dummy-data/train/*.tfrecords\n",
      "Training dataset has: -2 entries\n",
      "Trying to read eval data from path: gs://yejingxin-us-central2/external/lg/dummy-data/valid/*tfrecords\n",
      "Eval dataset has: -2 entries\n",
      "number parameters: 0.029 billion\n",
      "Per train step, total TFLOPs will be 0.19, split as 94.79% learnable weight flops and 5.21% attention flops\n",
      "completed step: 0, seconds: 2.360, TFLOP/s: 0.079, loss: 15.419\n",
      "To see full metrics 'tensorboard --logdir=gs://mazumdera-test-bucket/maxtext/lg/10142023/1/1xv3-8/tensorboard/'\n",
      "completed step: 1, seconds: 0.892, TFLOP/s: 0.208, loss: 15.397\n",
      "completed step: 2, seconds: 0.037, TFLOP/s: 5.058, loss: 15.382\n",
      "completed step: 3, seconds: 0.037, TFLOP/s: 4.989, loss: 15.308\n",
      "completed step: 4, seconds: 0.037, TFLOP/s: 5.061, loss: 15.243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 09:05:40.765354: I external/tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2023-10-14 09:05:40.765401: I external/tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed step: 5, seconds: 0.037, TFLOP/s: 5.038, loss: 15.171\n",
      "completed step: 6, seconds: 0.037, TFLOP/s: 4.961, loss: 15.123\n",
      "completed step: 7, seconds: 0.038, TFLOP/s: 4.884, loss: 15.025\n",
      "completed step: 8, seconds: 0.037, TFLOP/s: 4.953, loss: 15.006\n",
      "completed step: 9, seconds: 0.038, TFLOP/s: 4.890, loss: 14.934\n",
      "completed step: 10, seconds: 0.037, TFLOP/s: 5.036, loss: 14.861\n",
      "completed step: 11, seconds: 0.039, TFLOP/s: 4.764, loss: 14.820\n",
      "completed step: 12, seconds: 0.037, TFLOP/s: 5.068, loss: 14.739\n",
      "completed step: 13, seconds: 0.035, TFLOP/s: 5.246, loss: 14.701\n",
      "completed step: 14, seconds: 0.034, TFLOP/s: 5.435, loss: 14.659\n",
      "completed step: 15, seconds: 0.037, TFLOP/s: 5.051, loss: 14.671\n",
      "completed step: 16, seconds: 0.037, TFLOP/s: 5.061, loss: 14.665\n",
      "completed step: 17, seconds: 0.036, TFLOP/s: 5.151, loss: 14.626\n",
      "completed step: 18, seconds: 0.034, TFLOP/s: 5.418, loss: 14.617\n",
      "completed step: 19, seconds: 0.033, TFLOP/s: 5.554, loss: 14.614\n",
      "completed step: 20, seconds: 0.035, TFLOP/s: 5.353, loss: 14.601\n",
      "completed step: 21, seconds: 0.034, TFLOP/s: 5.519, loss: 14.589\n",
      "completed step: 22, seconds: 0.033, TFLOP/s: 5.554, loss: 14.576\n",
      "completed step: 23, seconds: 0.033, TFLOP/s: 5.656, loss: 14.561\n",
      "completed step: 24, seconds: 0.034, TFLOP/s: 5.404, loss: 14.574\n",
      "completed step: 25, seconds: 0.033, TFLOP/s: 5.632, loss: 14.536\n",
      "completed step: 26, seconds: 0.033, TFLOP/s: 5.645, loss: 14.485\n",
      "completed step: 27, seconds: 0.036, TFLOP/s: 5.129, loss: 14.479\n",
      "completed step: 28, seconds: 0.033, TFLOP/s: 5.581, loss: 14.468\n",
      "completed step: 29, seconds: 0.034, TFLOP/s: 5.475, loss: 14.392\n",
      "completed step: 30, seconds: 0.033, TFLOP/s: 5.666, loss: 14.368\n",
      "completed step: 31, seconds: 0.034, TFLOP/s: 5.507, loss: 14.272\n",
      "completed step: 32, seconds: 0.032, TFLOP/s: 5.758, loss: 14.223\n",
      "completed step: 33, seconds: 0.033, TFLOP/s: 5.633, loss: 14.151\n",
      "completed step: 34, seconds: 0.032, TFLOP/s: 5.744, loss: 14.059\n",
      "completed step: 35, seconds: 0.032, TFLOP/s: 5.773, loss: 13.998\n",
      "completed step: 36, seconds: 0.032, TFLOP/s: 5.746, loss: 13.904\n",
      "completed step: 37, seconds: 0.032, TFLOP/s: 5.801, loss: 13.800\n",
      "completed step: 38, seconds: 0.033, TFLOP/s: 5.589, loss: 13.715\n",
      "completed step: 39, seconds: 0.032, TFLOP/s: 5.861, loss: 13.609\n",
      "completed step: 40, seconds: 0.032, TFLOP/s: 5.858, loss: 13.536\n",
      "completed step: 41, seconds: 0.031, TFLOP/s: 5.975, loss: 13.428\n",
      "completed step: 42, seconds: 0.032, TFLOP/s: 5.823, loss: 13.372\n",
      "completed step: 43, seconds: 0.032, TFLOP/s: 5.836, loss: 13.259\n",
      "completed step: 44, seconds: 0.032, TFLOP/s: 5.878, loss: 13.189\n",
      "completed step: 45, seconds: 0.031, TFLOP/s: 5.907, loss: 13.120\n",
      "completed step: 46, seconds: 0.031, TFLOP/s: 5.920, loss: 13.050\n",
      "completed step: 47, seconds: 0.032, TFLOP/s: 5.807, loss: 12.980\n",
      "completed step: 48, seconds: 0.032, TFLOP/s: 5.736, loss: 12.965\n",
      "completed step: 49, seconds: 0.032, TFLOP/s: 5.835, loss: 12.903\n",
      "completed step: 50, seconds: 0.032, TFLOP/s: 5.784, loss: 12.882\n",
      "completed step: 51, seconds: 0.032, TFLOP/s: 5.784, loss: 12.854\n",
      "completed step: 52, seconds: 0.032, TFLOP/s: 5.740, loss: 12.837\n",
      "completed step: 53, seconds: 0.033, TFLOP/s: 5.595, loss: 12.823\n",
      "completed step: 54, seconds: 0.033, TFLOP/s: 5.662, loss: 12.802\n",
      "completed step: 55, seconds: 0.032, TFLOP/s: 5.752, loss: 12.824\n",
      "saved a checkpoint at step 55\n",
      "completed step: 56, seconds: 68.017, TFLOP/s: 0.003, loss: 12.796\n",
      "completed step: 57, seconds: 0.036, TFLOP/s: 5.206, loss: 12.787\n",
      "completed step: 58, seconds: 0.039, TFLOP/s: 4.796, loss: 12.771\n",
      "completed step: 59, seconds: 0.038, TFLOP/s: 4.889, loss: 12.757\n",
      "completed step: 60, seconds: 0.036, TFLOP/s: 5.205, loss: 12.739\n",
      "saved a checkpoint at step 60\n",
      "completed step: 61, seconds: 64.512, TFLOP/s: 0.003, loss: 12.738\n",
      "completed step: 62, seconds: 0.034, TFLOP/s: 5.534, loss: 12.720\n",
      "completed step: 63, seconds: 0.033, TFLOP/s: 5.631, loss: 12.701\n",
      "completed step: 64, seconds: 0.033, TFLOP/s: 5.688, loss: 12.656\n",
      "completed step: 65, seconds: 0.033, TFLOP/s: 5.653, loss: 12.642\n",
      "saved a checkpoint at step 65\n",
      "completed step: 66, seconds: 53.429, TFLOP/s: 0.003, loss: 12.569\n",
      "completed step: 67, seconds: 0.033, TFLOP/s: 5.686, loss: 12.524\n",
      "completed step: 68, seconds: 0.033, TFLOP/s: 5.585, loss: 12.480\n",
      "completed step: 69, seconds: 0.033, TFLOP/s: 5.593, loss: 12.444\n",
      "completed step: 70, seconds: 0.033, TFLOP/s: 5.581, loss: 12.362\n",
      "saved a checkpoint at step 70\n",
      "completed step: 71, seconds: 50.307, TFLOP/s: 0.004, loss: 12.319\n",
      "completed step: 72, seconds: 0.033, TFLOP/s: 5.649, loss: 12.259\n",
      "completed step: 73, seconds: 0.033, TFLOP/s: 5.690, loss: 12.224\n",
      "completed step: 74, seconds: 0.032, TFLOP/s: 5.746, loss: 12.148\n",
      "completed step: 75, seconds: 0.032, TFLOP/s: 5.739, loss: 12.119\n",
      "saved a checkpoint at step 75\n",
      "completed step: 76, seconds: 47.093, TFLOP/s: 0.004, loss: 12.050\n",
      "completed step: 77, seconds: 0.032, TFLOP/s: 5.768, loss: 12.011\n",
      "completed step: 78, seconds: 0.033, TFLOP/s: 5.621, loss: 11.967\n",
      "completed step: 79, seconds: 0.033, TFLOP/s: 5.699, loss: 11.921\n",
      "completed step: 80, seconds: 0.032, TFLOP/s: 5.738, loss: 11.895\n",
      "saved a checkpoint at step 80\n",
      "completed step: 81, seconds: 43.128, TFLOP/s: 0.004, loss: 11.858\n",
      "completed step: 82, seconds: 0.033, TFLOP/s: 5.542, loss: 11.840\n",
      "completed step: 83, seconds: 0.033, TFLOP/s: 5.612, loss: 11.810\n",
      "completed step: 84, seconds: 0.032, TFLOP/s: 5.724, loss: 11.811\n",
      "completed step: 85, seconds: 0.032, TFLOP/s: 5.717, loss: 11.795\n",
      "saved a checkpoint at step 85\n",
      "completed step: 86, seconds: 42.355, TFLOP/s: 0.004, loss: 11.783\n",
      "completed step: 87, seconds: 0.034, TFLOP/s: 5.493, loss: 11.756\n",
      "completed step: 88, seconds: 0.033, TFLOP/s: 5.619, loss: 11.752\n",
      "completed step: 89, seconds: 0.033, TFLOP/s: 5.661, loss: 11.752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 09:11:52.437660: I external/tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2023-10-14 09:12:15.850645: I external/tsl/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: gs://mazumdera-test-bucket/maxtext/lg/10142023/1/1xv3-8/tensorboard/plugins/profile/2023_10_14_09_12_13/t1v-n-8e231585-w-0.xplane.pb\n",
      "2023-10-14 09:12:24.575929: I external/tsl/tsl/profiler/rpc/client/save_profile.cc:117] Creating directory: gs://mazumdera-test-bucket/maxtext/lg/10142023/1/1xv3-8/tensorboard/plugins/profile/2023_10_14_09_12_13\n",
      "\n",
      "2023-10-14 09:12:30.069546: I external/tsl/tsl/profiler/rpc/client/save_profile.cc:123] Dumped gzipped tool data for trace.json.gz to gs://mazumdera-test-bucket/maxtext/lg/10142023/1/1xv3-8/tensorboard/plugins/profile/2023_10_14_09_12_13/t1v-n-8e231585-w-0.trace.json.gz\n",
      "2023-10-14 09:12:30.518623: I external/tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n"
     ]
    }
   ],
   "source": [
    "from train import calculate_num_params_from_pytree\n",
    "import max_logging\n",
    "import train\n",
    "\n",
    "writer = SummaryWriter(config.tensorboard_dir)\n",
    "\n",
    "learning_rate_schedule = max_utils.create_learning_rate_schedule(config)\n",
    "data_iterator = create_data_iterator_with_tokenizer(config, mesh)\n",
    "\n",
    "data_pspec = P(*config.data_sharding)\n",
    "\n",
    "\n",
    "num_model_parameters = calculate_num_params_from_pytree(state_read_from_ckpt.params)\n",
    "max_logging.log(f\"number parameters: {num_model_parameters/10**9:.3f} billion\")\n",
    "per_device_tflops = train.calculate_training_tflops(num_model_parameters, config)\n",
    "\n",
    "# Define compiled top-level functions.\n",
    "state_mesh_shardings_read_from_ckpt = jax.tree_map(\n",
    "  lambda p: jax.sharding.NamedSharding(mesh, p), state_mesh_annotations_read_from_ckpt)\n",
    "data_sharding = jax.tree_map(\n",
    "  lambda p: jax.sharding.NamedSharding(mesh, p), data_pspec)\n",
    "p_train_step = jax.jit(\n",
    "train.train_step,\n",
    "in_shardings=(state_mesh_shardings_read_from_ckpt, data_sharding, None),\n",
    "  out_shardings=(state_mesh_shardings_read_from_ckpt, None, None),\n",
    "static_argnums=(0,1,),\n",
    "donate_argnums=2)\n",
    "\n",
    "example_batch = None\n",
    "last_step_completion = datetime.datetime.now()\n",
    "\n",
    "local_metrics_file = open(config.metrics_file, 'a', encoding=\"utf8\") if config.metrics_file else None\n",
    "running_gcs_metrics = [] if config.gcs_metrics else None\n",
    "\n",
    "#ckpt was for step=50, let us train 40 more steps\n",
    "step = 90\n",
    "for step in np.arange(train.get_first_step(state_read_from_ckpt), step):\n",
    "    example_batch = train.load_next_batch(data_iterator, example_batch, config)\n",
    "    with mesh, nn_partitioning.axis_rules(config.logical_axis_rules):\n",
    "      state_read_from_ckpt, metrics, nextrng = p_train_step(\n",
    "          model, config, state_read_from_ckpt, example_batch, nextrng\n",
    "      )\n",
    "    \n",
    "    new_time = datetime.datetime.now()\n",
    "    train.record_scalar_metrics(metrics, new_time - last_step_completion,  per_device_tflops, learning_rate_schedule(step))\n",
    "    train.write_metrics(writer, metrics, step, config)\n",
    "    last_step_completion = new_time\n",
    "    \n",
    "    if checkpoint_manager is not None:\n",
    "      if checkpoint_manager.save(step, state_read_from_ckpt):\n",
    "        max_logging.log(f\"saved a checkpoint at step {step}\")\n",
    "      # Upon preemption, exit when and only when all ongoing saves are complete.\n",
    "      if checkpoint_manager.reached_preemption(step):\n",
    "        checkpoint_manager.wait_until_finished()\n",
    "        sys.exit()\n",
    "    \n",
    "    if config.metrics_file:\n",
    "      max_utils.write_metrics_locally(metrics, step, config, local_metrics_file)\n",
    "    \n",
    "    if config.gcs_metrics and jax.process_index() == 0:\n",
    "      running_gcs_metrics = max_utils.write_metrics_for_gcs(metrics, step, config, running_gcs_metrics)\n",
    "    \n",
    "    # Start profiling at end of first step to avoid compilation.\n",
    "    # Move before for loop to include.\n",
    "    if step == 0:\n",
    "      max_utils.activate_profiler(config)\n",
    "\n",
    "max_utils.deactivate_profiler(config)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c2273e-5566-4684-8865-661cef1362d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
