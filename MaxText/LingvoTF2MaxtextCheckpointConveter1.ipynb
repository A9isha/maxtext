{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e206924c-0576-4624-9225-d283ebb135db",
   "metadata": {},
   "source": [
    "#Note: Move this to the home directory of your TPU if you want to load both LingvoTF and MaxText config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22f035ca-1b95-4414-a224-9896c909e420",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-12 21:39:34.032357: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-10-12 21:39:34.032394: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "#the Lingvot TF experiment\n",
    "module = importlib.import_module('lg-gpt3.lingvo.tasks.lm.params.lg_gpt3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff9e1f7b-5cac-406f-a5e8-5cb2275d1dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'lg-gpt3.lingvo.tasks.lm.params.lg_gpt3' from '/home/mazumdera/lg-gpt3/lingvo/tasks/lm/params/lg_gpt3.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f837b494-9f12-405f-981c-501924117460",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-12 21:39:42.448568: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-10-12 21:39:42.448599: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-10-12 21:39:42.448630: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (t1v-n-8e231585-w-0): /proc/driver/nvidia/version does not exist\n",
      "2023-10-12 21:39:42.449070: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:absl:gshard_utils.Split is deprecated. Please use gshard_utils.MeshSplit with specific device_mesh and device_mesh_shape set in the Builder.\n",
      "WARNING:absl:gshard_utils.Split is deprecated. Please use gshard_utils.MeshSplit with specific device_mesh and device_mesh_shape set in the Builder.\n",
      "WARNING:absl:gshard_utils.Split is deprecated. Please use gshard_utils.MeshSplit with specific device_mesh and device_mesh_shape set in the Builder.\n",
      "WARNING:absl:gshard_utils.Split is deprecated. Please use gshard_utils.MeshSplit with specific device_mesh and device_mesh_shape set in the Builder.\n",
      "WARNING:absl:gshard_utils.Split is deprecated. Please use gshard_utils.MeshSplit with specific device_mesh and device_mesh_shape set in the Builder.\n",
      "WARNING:absl:gshard_utils.Split is deprecated. Please use gshard_utils.MeshSplit with specific device_mesh and device_mesh_shape set in the Builder.\n"
     ]
    }
   ],
   "source": [
    "import lingvo.compat as tf\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "tf_model = module.LgTestModel().Task()\n",
    "tf_model = tf_model.Instantiate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae2064f4-b6fe-4b7d-bcfd-c6e7e72dff54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lingvo.core.gshard_builder.UniTransformer at 0x7fccc8ca23b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7cd82d-9b37-484a-940e-3fde34890b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the checkpoint if not already done\n",
    "#!gsutil -m cp -r  \"gs://mazumdera-test-bucket/lingvo/v4-16-LgTestModel-10102023-1/train/*\" ~/lg-lingvo-checkpoint/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6128ae5-8ae5-42f2-962e-8f76f5c31918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "tf_path = os.path.abspath(\n",
    "    './lg-lingvo-checkpoint')  # Path to our TensorFlow checkpoint\n",
    "\n",
    "#load the Lingvo TF checkpoint\n",
    "reader=tf.train.load_checkpoint(tf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "864f8352-3584-4b2c-8cc3-5cb762f3fa8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transformer/decoder/final_layer_norm/w/scale/var/Adafactor': [512],\n",
       " 'transformer/decoder/final_layer_norm/w/scale/var': [512],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_000/dec_self_attention/w/wo/var/Adafactor': [384],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_000/dec_self_attention/w/wo/var': [384,\n",
       "  512],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_000/dec_self_attention/w/wk/var/Adafactor_1': [512],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_000/dec_self_attention/w/wk/var/Adafactor': [384],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_000/dec_self_attention/w/wo/var/Adafactor_1': [512],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_001/dense_relu_dense/w/wo/var': [2048,\n",
       "  512],\n",
       " 'transformer/dec_pos_emb/w/embedding/var/Adafactor': [512],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_000/ln/w/scale/var/Adafactor': [512],\n",
       " 'transformer/dec_emb/w/embedding/var/Adafactor_1': [50272],\n",
       " 'transformer/dec_emb/w/embedding/var/Adafactor': [512],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_000/dec_self_attention/w/wk/var': [512,\n",
       "  384],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_000/dec_self_attention/w/wq/var/Adafactor_1': [512],\n",
       " 'transformer/dec_emb/w/embedding/var': [50272, 512],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_000/ln/w/scale/var': [512],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_001/dense_relu_dense/w/wi/var': [512,\n",
       "  2048],\n",
       " 'transformer/dec_pos_emb/w/embedding/var/Adafactor_1': [2048],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_000/dec_self_attention/w/wv/var/Adafactor': [384],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_001/dense_relu_dense/w/wo/var/Adafactor_1': [2048],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_000/dec_self_attention/w/wq/var': [512,\n",
       "  384],\n",
       " 'global_step': [],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_001/dense_relu_dense/w/wo/var/Adafactor': [512],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_000/dec_self_attention/w/wq/var/Adafactor': [384],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_001/dense_relu_dense/w/wi/var/Adafactor_1': [2048],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_000/dec_self_attention/w/wv/var': [512,\n",
       "  384],\n",
       " 'transformer/dec_pos_emb/w/embedding/var': [2048, 512],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_000/dec_self_attention/w/wv/var/Adafactor_1': [512],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_001/dense_relu_dense/w/wi/var/Adafactor': [512],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_001/ln/w/scale/var': [512],\n",
       " 'transformer/decoder/blocks/iter_00000/blocks_body/layer_001/ln/w/scale/var/Adafactor': [512]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_shape_map = reader.get_variable_to_shape_map()\n",
    "ckpt_shape_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c67a2eb-28bb-4a31-a30d-80043574a786",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-12 21:39:59.283759: I external/xla/xla/pjrt/pjrt_api.cc:96] GetPjrtApi was found for tpu at /home/mazumdera/anaconda3/envs/py310/lib/python3.10/site-packages/libtpu/libtpu.so\n",
      "2023-10-12 21:39:59.283793: I external/xla/xla/pjrt/pjrt_api.cc:69] PJRT plugin for tpu has PJRT API version 0.12. The framework PJRT API version is 0.12.\n",
      "2023-10-12 21:39:59.283808: I external/xla/xla/pjrt/pjrt_api.cc:58] PJRT_Api is set for device type tpu\n",
      "2023-10-12 21:39:59.284182: I external/xla/xla/stream_executor/tpu/tpu_initializer_helper.cc:282] Libtpu path is: /home/mazumdera/anaconda3/envs/py310/lib/python3.10/site-packages/libtpu/libtpu.so\n",
      "2023-10-12 21:40:01.706859: I external/xla/xla/pjrt/pjrt_c_api_client.cc:95] PjRtCApiClient created.\n",
      "2023-10-12 21:40:01.720418: I external/xla/xla/pjrt/tfrt_cpu_pjrt_client.cc:462] TfrtCpuClient created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 devices.\n"
     ]
    }
   ],
   "source": [
    "#Get all the imports\n",
    "import jax\n",
    "import os\n",
    "import sys\n",
    "\n",
    "jax.config.update('jax_default_prng_impl', 'unsafe_rbg')\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"0\"\n",
    "os.environ[\"LIBTPU_INIT_ARGS\"] = os.environ.get(\"LIBTPU_INIT_ARGS\",\"\") + \" --xla_tpu_spmd_rng_bit_generator_unsafe=true\"\n",
    "print(f\"Found {jax.device_count()} devices.\")\n",
    "\n",
    "from typing import Sequence\n",
    "import datetime\n",
    "from absl import app\n",
    "from flax.linen import partitioning as nn_partitioning\n",
    "from flax import linen as nn\n",
    "import numpy as np\n",
    "import optax\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from layers import Transformer\n",
    "import pyconfig\n",
    "from input_pipeline import create_data_iterator_with_tokenizer\n",
    "import max_utils\n",
    "import checkpointing\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from jax.sharding import PartitionSpec as P\n",
    "from jax.sharding import Mesh\n",
    "\n",
    "from jax.experimental.compilation_cache import compilation_cache as cc\n",
    "\n",
    "from cloud_tpu_diagnostics import diagnostic\n",
    "from cloud_tpu_diagnostics.configuration import debug_configuration\n",
    "from cloud_tpu_diagnostics.configuration import diagnostic_configuration\n",
    "from cloud_tpu_diagnostics.configuration import stack_trace_configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aec9ef4b-010d-4654-8756-4b2dc11ce76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax.training import train_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d997407-6722-41c1-a952-a75df890866d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_output_directory=\"base_output_directory=gs://mazumdera-test-bucket/maxtext/lg/10112023/1\"\n",
    "file_pattern_for_train_data=\"file_pattern_for_train_data=gs://yejingxin-us-central2/external/lg/dummy-data/train/*.tfrecords\"\n",
    "file_pattern_for_eval_data=\"file_pattern_for_eval_data=gs://yejingxin-us-central2/external/lg/dummy-data/valid/*tfrecords\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "df634dba-1afd-4686-bc4f-0e02e462aa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "commandline_args = [\"dummy\", \"/home/mazumdera/maxtext/MaxText/configs/base.yml\",\"run_name=1xv3-8\", \"dcn_data_parallelism=1\", \"save_period=5\",\"ici_data_parallelism=4\",\"ici_tensor_parallelism=2\",\"steps=20\",\"enable_profiler=true\",\"remat_policy=full\",\"base_emb_dim=512\",\"base_num_heads=64\",\"head_dim=64\",\"vocab_size=50272\",\"base_num_decoder_layers=1\",\"per_device_batch_size=0.5\",\"enable_profiler=true\", \"base_mlp_dim=2048\", file_pattern_for_train_data, file_pattern_for_eval_data, base_output_directory,\"dataset_type=\\\"lg\\\"\",\"max_predict_length=512\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d3d3587f-6061-476a-aabb-514e52852b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyconfig.initialize(commandline_args)\n",
    "config = pyconfig.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2de289f-6468-48cd-bc4c-899d614e7f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating checkpoint manager...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-12 21:40:17.082218: I external/xla/xla/pjrt/distributed/service.cc:492] Experimental coordination service is enabled.\n",
      "2023-10-12 21:40:17.082519: I external/xla/xla/pjrt/distributed/service.cc:524] Jax service listening on 10.128.0.69:35353\n",
      "2023-10-12 21:40:17.083274: I external/tsl/tsl/distributed_runtime/coordination/coordination_service.cc:551] /job:jax_worker/replica:0/task:0 has connected to coordination service. Incarnation: 17886948029794908882\n",
      "2023-10-12 21:40:17.083432: I external/tsl/tsl/distributed_runtime/coordination/coordination_service_agent.cc:299] Coordination agent has successfully connected.\n",
      "2023-10-12 21:40:17.083748: I external/xla/xla/pjrt/distributed/client.cc:508] Connected to distributed JAX controller\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint manager created!\n"
     ]
    }
   ],
   "source": [
    "checkpoint_manager = checkpointing.create_orbax_checkpoint_manager(\n",
    "      config.checkpoint_dir,\n",
    "      config.enable_checkpointing,\n",
    "      config.async_checkpointing,\n",
    "      config.save_period,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c83c248d-20ba-4fb7-b207-b5c7ff42d1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial PRNG Keys\n",
    "init_rng, nextrng = random.split(random.PRNGKey(config.init_weights_seed), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8a14c500-a646-4f82-8a82-3702b16c26a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Devices: [TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0), TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1), TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0), TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1), TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0), TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1), TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0), TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)] (num_devices: 8)\n",
      "Decided on mesh: [[[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0)\n",
      "   TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1)]]\n",
      "\n",
      " [[TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0)\n",
      "   TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1)]]\n",
      "\n",
      " [[TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0)\n",
      "   TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]]\n",
      "\n",
      " [[TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0)\n",
      "   TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1)]]]\n"
     ]
    }
   ],
   "source": [
    "devices_array = max_utils.create_device_mesh(config)\n",
    "mesh = Mesh(devices_array, config.mesh_axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fd4ec8b3-c764-42f9-aa44-d58020e2b2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(config, mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e8c3219a-43ce-40dd-9ab6-87140245a933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: also compare with optax.adafactor\n",
    "tx = optax.adamw(\n",
    "      max_utils.create_learning_rate_schedule(config),\n",
    "      b1=config.adam_b1,\n",
    "      b2=config.adam_b2,\n",
    "      eps=config.adam_eps,\n",
    "      eps_root=config.adam_eps_root,\n",
    "      weight_decay=config.adam_weight_decay,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a65c97ad-03ee-48af-9bc8-af6407a79b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restoring state from this run's directory latest step         0\n"
     ]
    }
   ],
   "source": [
    "state, state_mesh_annotations = max_utils.setup_initial_state(model, tx, config, init_rng, mesh, checkpoint_manager)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "23992c32-f490-4636-9e0d-95996e662750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import max_utils\n",
    "init_train_state_partial = functools.partial(max_utils.init_train_state, model, tx,\n",
    "                                               config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "19c203e7-82ce-42a9-a6fd-1e80b1b654fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainState(step=ShapeDtypeStruct(shape=(), dtype=int32), apply_fn=<bound method Module.apply of Transformer(\n",
       "    # attributes\n",
       "    config = <pyconfig.HyperParameters object at 0x7fca62bd43a0>\n",
       "    mesh = Mesh(device_ids=array([[[0, 1]],\n",
       "    \n",
       "           [[2, 3]],\n",
       "    \n",
       "           [[6, 7]],\n",
       "    \n",
       "           [[4, 5]]]), axis_names=('data', 'fsdp', 'tensor'))\n",
       ")>, params={'decoder': {'decoder': {'mlp': {'wi': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 1, 2048), dtype=float32), names=('embed', 'layers', 'mlp'), mesh=None, rules=None)}, 'wo': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(2048, 1, 512), dtype=float32), names=('mlp', 'layers', 'embed'), mesh=None, rules=None)}}, 'pre_self_attention_layer_norm': {'scale': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 1), dtype=float32), names=('embed', 'layers'), mesh=None, rules=None)}, 'relpos_bias': {'rel_embedding': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(64, 1, 32), dtype=float32), names=('heads', 'layers', 'relpos_buckets'), mesh=None, rules=None)}, 'self_attention': {'key': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 1, 64, 64), dtype=float32), names=('embed', 'layers', 'heads', 'kv'), mesh=None, rules=None)}, 'key_layer_norm': {'scale': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(64, 1), dtype=float32), names=('heads', 'layers'), mesh=None, rules=None)}, 'out': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(64, 1, 64, 512), dtype=float32), names=('heads', 'layers', 'kv', 'embed'), mesh=None, rules=None)}, 'query': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 1, 64, 64), dtype=float32), names=('embed', 'layers', 'heads', 'kv'), mesh=None, rules=None)}, 'query_layer_norm': {'scale': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(64, 1), dtype=float32), names=('heads', 'layers'), mesh=None, rules=None)}, 'value': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 1, 64, 64), dtype=float32), names=('embed', 'layers', 'heads', 'kv'), mesh=None, rules=None)}}}, 'decoder_norm': {'scale': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512,), dtype=float32), names=('embed',), mesh=None, rules=None)}}, 'token_embedder': {'embedding': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(50272, 512), dtype=float32), names=('vocab', 'embed'), mesh=None, rules=None)}}, tx=GradientTransformationExtraArgs(init=<function chain.<locals>.init_fn at 0x7fca62ad3f40>, update=<function chain.<locals>.update_fn at 0x7fca62ad3490>), opt_state=(ScaleByAdamState(count=ShapeDtypeStruct(shape=(), dtype=int32), mu={'decoder': {'decoder': {'mlp': {'wi': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 1, 2048), dtype=float32), names=('embed', 'layers', 'mlp'), mesh=None, rules=None)}, 'wo': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(2048, 1, 512), dtype=float32), names=('mlp', 'layers', 'embed'), mesh=None, rules=None)}}, 'pre_self_attention_layer_norm': {'scale': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 1), dtype=float32), names=('embed', 'layers'), mesh=None, rules=None)}, 'relpos_bias': {'rel_embedding': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(64, 1, 32), dtype=float32), names=('heads', 'layers', 'relpos_buckets'), mesh=None, rules=None)}, 'self_attention': {'key': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 1, 64, 64), dtype=float32), names=('embed', 'layers', 'heads', 'kv'), mesh=None, rules=None)}, 'key_layer_norm': {'scale': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(64, 1), dtype=float32), names=('heads', 'layers'), mesh=None, rules=None)}, 'out': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(64, 1, 64, 512), dtype=float32), names=('heads', 'layers', 'kv', 'embed'), mesh=None, rules=None)}, 'query': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 1, 64, 64), dtype=float32), names=('embed', 'layers', 'heads', 'kv'), mesh=None, rules=None)}, 'query_layer_norm': {'scale': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(64, 1), dtype=float32), names=('heads', 'layers'), mesh=None, rules=None)}, 'value': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 1, 64, 64), dtype=float32), names=('embed', 'layers', 'heads', 'kv'), mesh=None, rules=None)}}}, 'decoder_norm': {'scale': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512,), dtype=float32), names=('embed',), mesh=None, rules=None)}}, 'token_embedder': {'embedding': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(50272, 512), dtype=float32), names=('vocab', 'embed'), mesh=None, rules=None)}}, nu={'decoder': {'decoder': {'mlp': {'wi': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 1, 2048), dtype=float32), names=('embed', 'layers', 'mlp'), mesh=None, rules=None)}, 'wo': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(2048, 1, 512), dtype=float32), names=('mlp', 'layers', 'embed'), mesh=None, rules=None)}}, 'pre_self_attention_layer_norm': {'scale': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 1), dtype=float32), names=('embed', 'layers'), mesh=None, rules=None)}, 'relpos_bias': {'rel_embedding': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(64, 1, 32), dtype=float32), names=('heads', 'layers', 'relpos_buckets'), mesh=None, rules=None)}, 'self_attention': {'key': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 1, 64, 64), dtype=float32), names=('embed', 'layers', 'heads', 'kv'), mesh=None, rules=None)}, 'key_layer_norm': {'scale': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(64, 1), dtype=float32), names=('heads', 'layers'), mesh=None, rules=None)}, 'out': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(64, 1, 64, 512), dtype=float32), names=('heads', 'layers', 'kv', 'embed'), mesh=None, rules=None)}, 'query': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 1, 64, 64), dtype=float32), names=('embed', 'layers', 'heads', 'kv'), mesh=None, rules=None)}, 'query_layer_norm': {'scale': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(64, 1), dtype=float32), names=('heads', 'layers'), mesh=None, rules=None)}, 'value': {'kernel': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512, 1, 64, 64), dtype=float32), names=('embed', 'layers', 'heads', 'kv'), mesh=None, rules=None)}}}, 'decoder_norm': {'scale': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(512,), dtype=float32), names=('embed',), mesh=None, rules=None)}}, 'token_embedder': {'embedding': LogicallyPartitioned(value=ShapeDtypeStruct(shape=(50272, 512), dtype=float32), names=('vocab', 'embed'), mesh=None, rules=None)}}), EmptyState(), ScaleByScheduleState(count=ShapeDtypeStruct(shape=(), dtype=int32))))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the flax.training.train_state.TrainState\n",
    "abstract_state = jax.eval_shape(init_train_state_partial, init_rng)\n",
    "abstract_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "52e2c259-9d85-4398-80c1-9d084734d1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainState(step=PartitionSpec(), apply_fn=<bound method Module.apply of Transformer(\n",
       "    # attributes\n",
       "    config = <pyconfig.HyperParameters object at 0x7fca62bd43a0>\n",
       "    mesh = Mesh(device_ids=array([[[0, 1]],\n",
       "    \n",
       "           [[2, 3]],\n",
       "    \n",
       "           [[6, 7]],\n",
       "    \n",
       "           [[4, 5]]]), axis_names=('data', 'fsdp', 'tensor'))\n",
       ")>, params={'decoder': {'decoder': {'mlp': {'wi': {'kernel': PartitionSpec('embed', 'layers', 'mlp')}, 'wo': {'kernel': PartitionSpec('mlp', 'layers', 'embed')}}, 'pre_self_attention_layer_norm': {'scale': PartitionSpec('embed', 'layers')}, 'relpos_bias': {'rel_embedding': PartitionSpec('heads', 'layers', 'relpos_buckets')}, 'self_attention': {'key': {'kernel': PartitionSpec('embed', 'layers', 'heads', 'kv')}, 'key_layer_norm': {'scale': PartitionSpec('heads', 'layers')}, 'out': {'kernel': PartitionSpec('heads', 'layers', 'kv', 'embed')}, 'query': {'kernel': PartitionSpec('embed', 'layers', 'heads', 'kv')}, 'query_layer_norm': {'scale': PartitionSpec('heads', 'layers')}, 'value': {'kernel': PartitionSpec('embed', 'layers', 'heads', 'kv')}}}, 'decoder_norm': {'scale': PartitionSpec('embed',)}}, 'token_embedder': {'embedding': PartitionSpec('vocab', 'embed')}}, tx=GradientTransformationExtraArgs(init=<function chain.<locals>.init_fn at 0x7fca62ad3f40>, update=<function chain.<locals>.update_fn at 0x7fca62ad3490>), opt_state=(ScaleByAdamState(count=PartitionSpec(), mu={'decoder': {'decoder': {'mlp': {'wi': {'kernel': PartitionSpec('embed', 'layers', 'mlp')}, 'wo': {'kernel': PartitionSpec('mlp', 'layers', 'embed')}}, 'pre_self_attention_layer_norm': {'scale': PartitionSpec('embed', 'layers')}, 'relpos_bias': {'rel_embedding': PartitionSpec('heads', 'layers', 'relpos_buckets')}, 'self_attention': {'key': {'kernel': PartitionSpec('embed', 'layers', 'heads', 'kv')}, 'key_layer_norm': {'scale': PartitionSpec('heads', 'layers')}, 'out': {'kernel': PartitionSpec('heads', 'layers', 'kv', 'embed')}, 'query': {'kernel': PartitionSpec('embed', 'layers', 'heads', 'kv')}, 'query_layer_norm': {'scale': PartitionSpec('heads', 'layers')}, 'value': {'kernel': PartitionSpec('embed', 'layers', 'heads', 'kv')}}}, 'decoder_norm': {'scale': PartitionSpec('embed',)}}, 'token_embedder': {'embedding': PartitionSpec('vocab', 'embed')}}, nu={'decoder': {'decoder': {'mlp': {'wi': {'kernel': PartitionSpec('embed', 'layers', 'mlp')}, 'wo': {'kernel': PartitionSpec('mlp', 'layers', 'embed')}}, 'pre_self_attention_layer_norm': {'scale': PartitionSpec('embed', 'layers')}, 'relpos_bias': {'rel_embedding': PartitionSpec('heads', 'layers', 'relpos_buckets')}, 'self_attention': {'key': {'kernel': PartitionSpec('embed', 'layers', 'heads', 'kv')}, 'key_layer_norm': {'scale': PartitionSpec('heads', 'layers')}, 'out': {'kernel': PartitionSpec('heads', 'layers', 'kv', 'embed')}, 'query': {'kernel': PartitionSpec('embed', 'layers', 'heads', 'kv')}, 'query_layer_norm': {'scale': PartitionSpec('heads', 'layers')}, 'value': {'kernel': PartitionSpec('embed', 'layers', 'heads', 'kv')}}}, 'decoder_norm': {'scale': PartitionSpec('embed',)}}, 'token_embedder': {'embedding': PartitionSpec('vocab', 'embed')}}), EmptyState(), ScaleByScheduleState(count=PartitionSpec())))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "state_logical_annotations = nn.get_partition_spec(abstract_state)\n",
    "state_logical_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1b37f119-2941-4547-86f3-19c649261a1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainState(step=ShapeDtypeStruct(shape=(), dtype=int32), apply_fn=<bound method Module.apply of Transformer(\n",
       "    # attributes\n",
       "    config = <pyconfig.HyperParameters object at 0x7fca62bd43a0>\n",
       "    mesh = Mesh(device_ids=array([[[0, 1]],\n",
       "    \n",
       "           [[2, 3]],\n",
       "    \n",
       "           [[6, 7]],\n",
       "    \n",
       "           [[4, 5]]]), axis_names=('data', 'fsdp', 'tensor'))\n",
       ")>, params={'decoder': {'decoder': {'mlp': {'wi': {'kernel': ShapeDtypeStruct(shape=(512, 1, 2048), dtype=float32)}, 'wo': {'kernel': ShapeDtypeStruct(shape=(2048, 1, 512), dtype=float32)}}, 'pre_self_attention_layer_norm': {'scale': ShapeDtypeStruct(shape=(512, 1), dtype=float32)}, 'relpos_bias': {'rel_embedding': ShapeDtypeStruct(shape=(64, 1, 32), dtype=float32)}, 'self_attention': {'key': {'kernel': ShapeDtypeStruct(shape=(512, 1, 64, 64), dtype=float32)}, 'key_layer_norm': {'scale': ShapeDtypeStruct(shape=(64, 1), dtype=float32)}, 'out': {'kernel': ShapeDtypeStruct(shape=(64, 1, 64, 512), dtype=float32)}, 'query': {'kernel': ShapeDtypeStruct(shape=(512, 1, 64, 64), dtype=float32)}, 'query_layer_norm': {'scale': ShapeDtypeStruct(shape=(64, 1), dtype=float32)}, 'value': {'kernel': ShapeDtypeStruct(shape=(512, 1, 64, 64), dtype=float32)}}}, 'decoder_norm': {'scale': ShapeDtypeStruct(shape=(512,), dtype=float32)}}, 'token_embedder': {'embedding': ShapeDtypeStruct(shape=(50272, 512), dtype=float32)}}, tx=GradientTransformationExtraArgs(init=<function chain.<locals>.init_fn at 0x7fca62ad3f40>, update=<function chain.<locals>.update_fn at 0x7fca62ad3490>), opt_state=(ScaleByAdamState(count=ShapeDtypeStruct(shape=(), dtype=int32), mu={'decoder': {'decoder': {'mlp': {'wi': {'kernel': ShapeDtypeStruct(shape=(512, 1, 2048), dtype=float32)}, 'wo': {'kernel': ShapeDtypeStruct(shape=(2048, 1, 512), dtype=float32)}}, 'pre_self_attention_layer_norm': {'scale': ShapeDtypeStruct(shape=(512, 1), dtype=float32)}, 'relpos_bias': {'rel_embedding': ShapeDtypeStruct(shape=(64, 1, 32), dtype=float32)}, 'self_attention': {'key': {'kernel': ShapeDtypeStruct(shape=(512, 1, 64, 64), dtype=float32)}, 'key_layer_norm': {'scale': ShapeDtypeStruct(shape=(64, 1), dtype=float32)}, 'out': {'kernel': ShapeDtypeStruct(shape=(64, 1, 64, 512), dtype=float32)}, 'query': {'kernel': ShapeDtypeStruct(shape=(512, 1, 64, 64), dtype=float32)}, 'query_layer_norm': {'scale': ShapeDtypeStruct(shape=(64, 1), dtype=float32)}, 'value': {'kernel': ShapeDtypeStruct(shape=(512, 1, 64, 64), dtype=float32)}}}, 'decoder_norm': {'scale': ShapeDtypeStruct(shape=(512,), dtype=float32)}}, 'token_embedder': {'embedding': ShapeDtypeStruct(shape=(50272, 512), dtype=float32)}}, nu={'decoder': {'decoder': {'mlp': {'wi': {'kernel': ShapeDtypeStruct(shape=(512, 1, 2048), dtype=float32)}, 'wo': {'kernel': ShapeDtypeStruct(shape=(2048, 1, 512), dtype=float32)}}, 'pre_self_attention_layer_norm': {'scale': ShapeDtypeStruct(shape=(512, 1), dtype=float32)}, 'relpos_bias': {'rel_embedding': ShapeDtypeStruct(shape=(64, 1, 32), dtype=float32)}, 'self_attention': {'key': {'kernel': ShapeDtypeStruct(shape=(512, 1, 64, 64), dtype=float32)}, 'key_layer_norm': {'scale': ShapeDtypeStruct(shape=(64, 1), dtype=float32)}, 'out': {'kernel': ShapeDtypeStruct(shape=(64, 1, 64, 512), dtype=float32)}, 'query': {'kernel': ShapeDtypeStruct(shape=(512, 1, 64, 64), dtype=float32)}, 'query_layer_norm': {'scale': ShapeDtypeStruct(shape=(64, 1), dtype=float32)}, 'value': {'kernel': ShapeDtypeStruct(shape=(512, 1, 64, 64), dtype=float32)}}}, 'decoder_norm': {'scale': ShapeDtypeStruct(shape=(512,), dtype=float32)}}, 'token_embedder': {'embedding': ShapeDtypeStruct(shape=(50272, 512), dtype=float32)}}), EmptyState(), ScaleByScheduleState(count=ShapeDtypeStruct(shape=(), dtype=int32))))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unboxed_abstract_state = max_utils.unbox_logicallypartioned_trainstate(abstract_state)\n",
    "unboxed_abstract_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "729f70c2-2cfa-487f-94ce-c71945cfc0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total num of params = 340142208\n"
     ]
    }
   ],
   "source": [
    "#Num of params in the MaxText config\n",
    "\n",
    "from train import calculate_num_params_from_pytree\n",
    "print(f\"Total num of params = {calculate_num_params_from_pytree(state.params)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a66526f-45d9-4884-9ebf-c7110af0297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us consider we are saving a state at step 0 at the vanilla state\n",
    "import max_logging\n",
    "step = 0\n",
    "if checkpoint_manager is not None:\n",
    "      if checkpoint_manager.save(step, state):\n",
    "        max_logging.log(f\"saved a checkpoint at step {step}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb2f9d4-4545-4ce4-a0e8-e2d7cfa43078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #since we know know we are loading checkpoint at step 50\n",
    "# step = 50\n",
    "# if checkpoint_manager is not None:\n",
    "#       if checkpoint_manager.save(step, state):\n",
    "#         max_logging.log(f\"saved a checkpoint at step {step}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "014f083d-6b6a-4ae4-a320-631efc792ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mlp', 'pre_self_attention_layer_norm', 'relpos_bias', 'self_attention'])\n"
     ]
    }
   ],
   "source": [
    "# all_keys = [key for key in state.params.keys]\n",
    "print(state.params['decoder']['decoder'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3e13314d-b282-427e-80ba-04f44c7c5f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mlp', 'pre_self_attention_layer_norm', 'relpos_bias', 'self_attention'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.params['decoder']['decoder'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "92f91f55-d9c7-404f-b297-c8bd5fc4e3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mlp', 'pre_self_attention_layer_norm', 'relpos_bias', 'self_attention'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.params['decoder']['decoder'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4b259a28-c256-4251-aca5-9a970c38bb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096, 1, 8192)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.params['decoder']['decoder']['mlp']['wi']['kernel'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c779cae-f6ef-48f1-8005-e03964204831",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
